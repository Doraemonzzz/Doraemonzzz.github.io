<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Doraemonzzz - Learn For Fun</title><meta name="author" content="Doraemonzzz"><meta name="copyright" content="Doraemonzzz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="Doraemonzzz">
<meta property="og:url" content="http://doraemonzzz.com/page/38/index.html">
<meta property="og:site_name" content="Doraemonzzz">
<meta property="og:description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:author" content="Doraemonzzz">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://doraemonzzz.com/page/38/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Doraemonzzz',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-06-08 00:56:56'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">610</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Doraemonzzz</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Doraemonzzz</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/02/10/CS231%20%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89/" title="CS231 第七讲 训练神经网络（下）">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231 第七讲 训练神经网络（下）"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/10/CS231%20%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89/" title="CS231 第七讲 训练神经网络（下）">CS231 第七讲 训练神经网络（下）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-10T06:37:00.000Z" title="发表于 2019-02-10 14:37:00">2019-02-10</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲继续介绍训练神经网络的一些技巧。

更好的优化之前我们介绍了随机梯度下降法，但是这个方法有一些问题——如果损失在某个方向降低很快，另一个方向降低很慢，那么图像如下

如果从红点出发，利用随机梯度下降法产生的结果非常震荡，这就会严重影响效率

另一个问题是，随机梯度下降很容易陷入局部最优点和马鞍点

还有一个问题是，随机梯度下降法很容易受到噪声干扰，这会让优化速度减慢

下面介绍几种处理上述问题的优化方法。
Momentum第一种方法是Momentum，其更新公式如下

\begin{aligned}
v_{t+1} &= \rho v_t + \nabla f(x_t) \\
x_{t+1}&= x_t -\alpha v_{t+1}
\end{aligned}伪代码如下
vx = 0
while True:
    dx = compute_gradient(x)
    vx = rho ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/02/10/Michael%20Collins%20NLP%20Lecture%204/" title="Michael Collins NLP Lecture 4">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Michael Collins NLP Lecture 4"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/10/Michael%20Collins%20NLP%20Lecture%204/" title="Michael Collins NLP Lecture 4">Michael Collins NLP Lecture 4</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-10T05:19:00.000Z" title="发表于 2019-02-10 13:19:00">2019-02-10</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">课程主页：http://www.cs.columbia.edu/~cs4705/
课程网盘地址：
链接：https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3 
这一讲主要介绍了语法解析(Parsing)以及上下文无关法(Context-Free Grammars)。

Chapter 3 概率上下文无关法(Probabilistic Context-Free Grammars (PCFGs))首先介绍语法解析问题，问题形式如下

语法解析的一个应用是机器翻译，因为不同语言中的语法有所不同，例如

本章介绍的概率上下文无关法为处理语法解析问题的一个常用方法，在此之前，我们先介绍上下文无关法(Context-Free Grammars)。
1.上下文无关法(Context-Free Grammars)1.1 基本定义上下文无关法(CFG)是一个四元组$G=(N,\Sigma,R,S)$，其中

$N$是一组有限的非终止符。
$\Sigma$一组有限的终止符。
$R$是形如$X\to Y_1Y_2…Y_n$的有限规则的集合，其中$X\ ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/02/04/Michael%20Collins%20NLP%20Lecture%203/" title="Michael Collins NLP Lecture 3">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Michael Collins NLP Lecture 3"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/04/Michael%20Collins%20NLP%20Lecture%203/" title="Michael Collins NLP Lecture 3">Michael Collins NLP Lecture 3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-04T09:06:00.000Z" title="发表于 2019-02-04 17:06:00">2019-02-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">课程主页：http://www.cs.columbia.edu/~cs4705/
课程网盘地址：
链接：https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3 
这一讲主要介绍了标注问题和隐马尔可夫模型。

Chapter 2 标注问题和隐马尔可夫模型2.1 介绍在许多NLP问题中，我们希望对序列对进行建模。词性（POS）标注可能是此类问题中最早，最著名的例子。 在POS标注中，我们的目标是建立一个模型，其输入为句子，例如

\text{the dog saw a cat}其输出是标注序列

\begin{eqnarray*}
\text{D N V D N}\tag{2.1} 
\end{eqnarray*}（这里我们使用D表示定冠词，N表示名词，V表示动词）。标签序列与输入句子的长度相同，因此为句子中的每个单词指定一个标签（在本例中D标注the，N标注dog，V标注saw，依此类推）。
​    我们将使用$x_1…x_n$来表示标注模型的输入：将其称为句子。在上面的例子中，我们的长度为$n=5$并且

x_1 =\text{ ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2022%20Radon%E6%B5%8B%E5%BA%A6%E4%B9%8B%E5%BE%AE%E5%88%86/" title="台大实分析单元 22 Radon测度之微分">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="台大实分析单元 22 Radon测度之微分"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2022%20Radon%E6%B5%8B%E5%BA%A6%E4%B9%8B%E5%BE%AE%E5%88%86/" title="台大实分析单元 22 Radon测度之微分">台大实分析单元 22 Radon测度之微分</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-04T05:30:00.000Z" title="发表于 2019-02-04 13:30:00">2019-02-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="content">然后介绍Radon导数的性质。

$\mu$是定义在$\Omega\subset \mathbb R^n$上的Radon测度（$\Omega$为开集），定义

\underline D \mu(x)=\underset {\Omega\supset B\to x}{\lim \inf} \frac {\mu(B)}{\lambda^n (B)}
=\lim_{\delta\to 0^+} \{\inf _{\delta B</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2021%20Riemann%20%E4%B8%8E%20Lebesgue%20%E7%A7%AF%E5%88%86%EF%BC%882%EF%BC%89/" title="台大实分析单元 21 Riemann 与 Lebesgue 积分（2）">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="台大实分析单元 21 Riemann 与 Lebesgue 积分（2）"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2021%20Riemann%20%E4%B8%8E%20Lebesgue%20%E7%A7%AF%E5%88%86%EF%BC%882%EF%BC%89/" title="台大实分析单元 21 Riemann 与 Lebesgue 积分（2）">台大实分析单元 21 Riemann 与 Lebesgue 积分（2）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-04T05:28:00.000Z" title="发表于 2019-02-04 13:28:00">2019-02-04</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="content">这一部分继续介绍Riemann积分和Lebesgue积分的关系，然后介绍Radon测度的导数。

Theorem 1
f在I上黎曼可积当且仅当在I上几乎处处连续证明：假设$f$在$I$上黎曼可积，那么

\int_I \underline  f d\lambda^n=\underline \int_I f =\overline \int_I f
 =\int_I \overline f d\lambda^n所以

\int_I (\bar f -\underline  f ) d\lambda^n =0因为$\bar f \ge \underline f$，所以在$I$上

\bar f =\underline f\ \ (a.e)即在$I$上

\bar f =f=\underline f\ \ (a.e)因此$f$在$I$上几乎处处连续。
反之，如果$f$在$I$上几乎处处连续，那么在$I$上

\bar f =f=\underline f\ \ (a.e)因此

\underline \int_I f =\int_I \underline  f d\lambda^n
 =\int ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/02/02/CS231%20%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89/" title="CS231 第六讲 训练神经网络（上）">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231 第六讲 训练神经网络（上）"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/02/CS231%20%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89/" title="CS231 第六讲 训练神经网络（上）">CS231 第六讲 训练神经网络（上）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-02T14:21:00.000Z" title="发表于 2019-02-02 22:21:00">2019-02-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲主要介绍训练神经网络的一些技巧。

激活函数回顾神经元的架构

我们首先进行线性运算，接着使用激活函数$f$，常用激活函数如下

下面分别介绍这几个激活函数。
Sigmoid
Sigmoid函数有如下三个问题：

1.饱和的神经元会使得梯度消失。
这是因为当$x$绝对值很大时，Sigmoid函数的导数几乎为$0$（这点从图像中就能看出），而这会使训练过程很缓慢。

2.Sigmoid函数输出结果的均值不是$0$。
由于Sigmoid函数输出结果都大于$0$，由乘法门的含义可知，这会导致梯度的符号都相同，这也不利于训练。

3.$\exp()$有一定的计算量。
这个算是比较次要的原因，感觉主要是和之后的ReLU作对比。


tanh
tanh函数可以克服上述第2个问题，因为输出结果的均值为$0$，但是问题1,3依然没有解决。
ReLU
ReLU函数可以有效克服问题1，但是输出结果的均值不是$0 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/02/01/CS229%20Lesson%201%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/" title="CS229 Lesson 1 机器学习的动机与应用">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS229 Lesson 1 机器学习的动机与应用"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/02/01/CS229%20Lesson%201%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/" title="CS229 Lesson 1 机器学习的动机与应用">CS229 Lesson 1 机器学习的动机与应用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-02-01T14:36:00.000Z" title="发表于 2019-02-01 22:36:00">2019-02-01</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">课程视频地址：http://open.163.com/special/opencourse/machinelearning.html
课程主页：http://cs229.stanford.edu/
更具体的资料链接：https://www.jianshu.com/p/0a6ef31ff77a
笔记参考自中文翻译版：https://github.com/Kivy-CN/Stanford-CS-229-CN
整理完9到20讲之后开始回过头来整理前面8讲，第一讲主要对机器学习做了简介。

监督式学习让我们首先谈谈监督学习问题的几个例子。假设我们有一个数据集，给出了俄勒冈州波特兰市47所房屋的房间大小和价格：

​    作图可得：

​    根据这样的数据，我们如何根据房间大小来学习预测波特兰其他房屋的价格？
​    我们将使用$x^{(i)}$来表示“输入”变量（这个例子中为房间大小），也称为输入特征，$y^{(i)}$表示“输出”或我们正试图预测的目标变量（此处为价格）。 一对$(x^{(i)},y^{(i)})$被称为训练样本，我们将用于学习的数据集——$m$个训练样本$\{(x^ ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/01/31/CS231%20%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="CS231 第五讲 卷积神经网络">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CS231 第五讲 卷积神经网络"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/01/31/CS231%20%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="CS231 第五讲 卷积神经网络">CS231 第五讲 卷积神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-01-31T14:42:00.000Z" title="发表于 2019-01-31 22:42:00">2019-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲主要介绍卷积神经网络。

第一部分是介绍历史，这里略过，直接进入正题。
卷积神经网络卷积神经网络主要用于计算机视觉领域，处理对象为图片，首先来比较卷积神经网络和之前介绍的神经网络的区别。
之前介绍的神经网络每层被称为全连接层，形式如下

而卷积神经网络有卷积层，形式如下

那么为什么要使用卷积层而不是全连接层呢？主要如下两个原因。第一个原因是全连接层的权重太多，例如$200\times 200\times 3$的图像将有$120,000$个权重，这很容易导致过拟合（参数太多）以及计算成本太大；第二个原因是图像中有很多模式重复出现，例如边缘等等，使用滤波器可以复用这些共同特征。
下面详细介绍卷积层。
卷积层下面假设图像的维度为$W_1 \times H_1 \times D_1​$，一般来说，滤波器前两个维度相等，而第三个维度必须等于图像的第三个维度，从而这里假设滤波器的维度为$F\times ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/01/31/Hexo%E5%8D%9A%E5%AE%A2deploy%E6%8A%A5%E9%94%99/" title="Hexo博客deploy报错">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo博客deploy报错"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/01/31/Hexo%E5%8D%9A%E5%AE%A2deploy%E6%8A%A5%E9%94%99/" title="Hexo博客deploy报错">Hexo博客deploy报错</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-01-31T14:25:28.000Z" title="发表于 2019-01-31 22:25:28">2019-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hexo/">Hexo</a></span></div><div class="content">今天hexo写博客的时候又遇到一个坑，这里简单记录下。

出现的问题是hexo d之后有如下报错：
Template render error: (unknown path) [Line 147, Column 121]
  expected variable end
网上查了下，发现原因是因为出现了如下形式的连续两个大括号：
&#123;&#123; ,&#125;&#125;
发现问题后，我让大括号之间带个空格，即使用：
&#123; &#123; ,&#125; &#125;
替换上述符号，果然解决了。
</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E4%BA%94%E8%AE%B2/" title="高等概率论第十五讲">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="高等概率论第十五讲"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E4%BA%94%E8%AE%B2/" title="高等概率论第十五讲">高等概率论第十五讲</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-01-31T14:00:50.000Z" title="发表于 2019-01-31 22:00:50">2019-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="content">记录本校的高等概率论课程笔记，参考教材《测度与概率》。
本讲介绍了强大数定律，特征函数以及中心极限定理。

2.(弱)大数定律(LLN)定理7.1.1
设\lbrace X_n\rbrace  \ iid,那么存在\lbrace a_n\rbrace 使得 \frac{S_n}{n}-a_n \overset{\mathbb P} \to 0 \Leftrightarrow
\lim_{x\to \infty} x \mathbb P (|X_1|>x)= 0证明：仅证明$\Leftarrow$：$\forall n \ge 1, 1\le k \le n$，定义

X_{nk}\triangleq X_k 1_{\lbrace  |X_k|\le n\rbrace  } ,\hat S_n =\sum_{k=1}^n X_{nk}不难看出$y_k=X_{nk}$独立同分布，则

\begin{aligned}
\frac 1{n^2} \text{Var}(\hat S_n) 
&=\frac 1 {n^2} \sum_{k=1}^n \text{Var}(X_{nk})\\
&\l ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E5%9B%9B%E8%AE%B2/" title="高等概率论第十四讲">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="高等概率论第十四讲"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E5%9B%9B%E8%AE%B2/" title="高等概率论第十四讲">高等概率论第十四讲</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-01-31T13:59:50.000Z" title="发表于 2019-01-31 21:59:50">2019-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="content">记录本校的高等概率论课程笔记，参考教材《测度与概率》。
本讲继续上次的内容并介绍弱大数定律。

定理 6.4.2
设\lbrace F_n,n\ge 1\rbrace 是\mathbb R^d上一列概率分布函数，则它一定有淡收敛子列证明：利用对角线方法。
记$Q= \lbrace r_1,r_2,…,r_n,…\rbrace $为全体有理数，因为$\lbrace F_n (r_1)\rbrace $有界，因此有收敛子列$\lbrace F_{1n} (r_1)\rbrace $，记

F_{1n} (r_1)\to F(r_1),n\to \infty因为$\lbrace F_{1n} (r_2)\rbrace $也有界，因此有收敛子列$\lbrace F_{2n} (r_2)\rbrace $，记

F_{2n} (r_2) \to F(r_2), n\to \infty注意$F_{1n}$在$r_1$收敛，$F_{2n}$在$r_1,r_2$收敛，如此下去，得到阵列

 \left(
 \begin{matrix}
   F_{11} & F_{12}& ... & F_{1n}& ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E4%B8%89%E8%AE%B2/" title="高等概率论第十三讲">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="高等概率论第十三讲"></a></div><div class="recent-post-info"><a class="article-title" href="/2019/01/31/%E9%AB%98%E7%AD%89%E6%A6%82%E7%8E%87%E8%AE%BA%E7%AC%AC%E5%8D%81%E4%B8%89%E8%AE%B2/" title="高等概率论第十三讲">高等概率论第十三讲</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2019-01-31T13:56:50.000Z" title="发表于 2019-01-31 21:56:50">2019-01-31</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="content">记录本校的高等概率论课程笔记，参考教材《测度与概率》。
本讲介绍了矩收敛，$L^r$收敛，依分布收敛以及概率测度的弱收敛。

3.矩收敛与$L^r$收敛1.$L^r$收敛$L^r$收敛的定义定义：

设(\Omega, \mathcal F, P)是一概率空间，定义L^r=L^r(\Omega, \mathcal F, P) =\{r.v\ \ X:\mathbb E|X|^r< \infty\}。\\若\{X;X_n ,n\ge 1\}\subset L^r且\mathbb E|x _n-x|^r \to 0，则称X_n \ r阶矩收敛于X，记为：\\
X_n \overset{r} \to  X  \ \ \ \ \ (n\to \infty)推论(1)
X_n \overset {r}\to X \Rightarrow X_n \overset{P}\to X \ \ \ \ \ (n\to \infty)证：$\forall \epsilon &gt;0$

\mathbb P(|X_n -X| \ge \epsilon) \le \epsilon^{-r} \mathbb E ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/37/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/#content-inner">37</a><span class="page-number current">38</span><a class="page-number" href="/page/39/#content-inner">39</a><span class="space">&hellip;</span><a class="page-number" href="/page/51/#content-inner">51</a><a class="extend next" rel="next" href="/page/39/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Doraemonzzz</div><div class="author-info__description">个人博客，主要记录有关机器学习，数学以及计算机科学的笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">610</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/06/06/2021-6-6-%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA(DPV)%E4%B9%A0%E9%A2%98%E8%A7%A3%E7%AD%94%E2%80%94%E2%80%94%E7%AC%AC3%E7%AB%A0-%E5%9B%BE%E7%9A%84%E5%88%86%E8%A7%A3/" title="算法概论(DPV)习题解答——第3章 图的分解"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法概论(DPV)习题解答——第3章 图的分解"/></a><div class="content"><a class="title" href="/2021/06/06/2021-6-6-%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA(DPV)%E4%B9%A0%E9%A2%98%E8%A7%A3%E7%AD%94%E2%80%94%E2%80%94%E7%AC%AC3%E7%AB%A0-%E5%9B%BE%E7%9A%84%E5%88%86%E8%A7%A3/" title="算法概论(DPV)习题解答——第3章 图的分解">算法概论(DPV)习题解答——第3章 图的分解</a><time datetime="2021-06-06T14:35:00.000Z" title="发表于 2021-06-06 22:35:00">2021-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/06/2021-6-6-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E7%AC%AC5%E7%AB%A0-%E4%B9%A0%E9%A2%98%E8%A7%A3%E6%9E%90/" title="深入理解计算机系统 第5章 习题解析"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深入理解计算机系统 第5章 习题解析"/></a><div class="content"><a class="title" href="/2021/06/06/2021-6-6-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E7%AC%AC5%E7%AB%A0-%E4%B9%A0%E9%A2%98%E8%A7%A3%E6%9E%90/" title="深入理解计算机系统 第5章 习题解析">深入理解计算机系统 第5章 习题解析</a><time datetime="2021-06-06T07:23:00.000Z" title="发表于 2021-06-06 15:23:00">2021-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/05/2021-6-5-Stanford-Compiler-PA5%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA5翻译"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Stanford Compiler PA5翻译"/></a><div class="content"><a class="title" href="/2021/06/05/2021-6-5-Stanford-Compiler-PA5%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA5翻译">Stanford Compiler PA5翻译</a><time datetime="2021-06-05T06:12:00.000Z" title="发表于 2021-06-05 14:12:00">2021-06-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/04/2021-6-4-Stanford-Compiler-PA4%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA4翻译"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Stanford Compiler PA4翻译"/></a><div class="content"><a class="title" href="/2021/06/04/2021-6-4-Stanford-Compiler-PA4%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA4翻译">Stanford Compiler PA4翻译</a><time datetime="2021-06-03T16:17:00.000Z" title="发表于 2021-06-04 00:17:00">2021-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/03/2021-6-3-%E5%B7%A7%E5%A6%99%E7%9A%84Y%E8%BF%90%E7%AE%97%E7%AC%A6/" title="巧妙的Y运算符"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="巧妙的Y运算符"/></a><div class="content"><a class="title" href="/2021/06/03/2021-6-3-%E5%B7%A7%E5%A6%99%E7%9A%84Y%E8%BF%90%E7%AE%97%E7%AC%A6/" title="巧妙的Y运算符">巧妙的Y运算符</a><time datetime="2021-06-03T00:54:00.000Z" title="发表于 2021-06-03 08:54:00">2021-06-03</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI/"><span class="card-category-list-name">AI</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C/"><span class="card-category-list-name">C++</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C%E8%AF%AD%E8%A8%80/"><span class="card-category-list-name">C语言</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo/"><span class="card-category-list-name">Hexo</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/JAVA/"><span class="card-category-list-name">JAVA</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">48</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python%E7%88%AC%E8%99%AB/"><span class="card-category-list-name">Python爬虫</span><span class="card-category-list-count">5</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Advanced-Machine-Learning/" style="font-size: 1.17em; color: #999c9f">Advanced Machine Learning</a> <a href="/tags/CMU-15-213/" style="font-size: 1.41em; color: #99a5b7">CMU 15-213</a> <a href="/tags/CS170/" style="font-size: 1.43em; color: #99a6b9">CS170</a> <a href="/tags/CS205A/" style="font-size: 1.43em; color: #99a6b9">CS205A</a> <a href="/tags/CS224N/" style="font-size: 1.39em; color: #99a5b4">CS224N</a> <a href="/tags/CS229/" style="font-size: 1.48em; color: #99a8bd">CS229</a> <a href="/tags/CS231/" style="font-size: 1.37em; color: #99a4b2">CS231</a> <a href="/tags/CS234-Reinforcement-Learning/" style="font-size: 1.1em; color: #999">CS234 Reinforcement Learning</a> <a href="/tags/CS236-Deep-Generative-Models/" style="font-size: 1.26em; color: #999fa8">CS236 Deep Generative Models</a> <a href="/tags/CS50/" style="font-size: 1.23em; color: #999ea6">CS50</a> <a href="/tags/CSE-351/" style="font-size: 1.34em; color: #99a3b0">CSE 351</a> <a href="/tags/DLHLP/" style="font-size: 1.23em; color: #999ea6">DLHLP</a> <a href="/tags/DSP/" style="font-size: 1.28em; color: #99a0aa">DSP</a> <a href="/tags/David-silver-Reinforcement-Learning/" style="font-size: 1.3em; color: #99a1ac">David silver Reinforcement Learning</a> <a href="/tags/EE261/" style="font-size: 1.5em; color: #99a9bf">EE261</a> <a href="/tags/EE263/" style="font-size: 1.46em; color: #99a7bb">EE263</a> <a href="/tags/EE364A/" style="font-size: 1.21em; color: #999da4">EE364A</a> <a href="/tags/From-Nand-to-Tetris/" style="font-size: 1.28em; color: #99a0aa">From Nand to Tetris</a> <a href="/tags/Hexo%E5%8D%9A%E5%AE%A2%E6%8A%A5%E9%94%99/" style="font-size: 1.19em; color: #999da1">Hexo博客报错</a> <a href="/tags/Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/" style="font-size: 1.1em; color: #999">Hoeffding不等式</a> <a href="/tags/MIT-%E6%A6%82%E7%8E%87%E5%85%AC%E5%BC%80%E8%AF%BE/" style="font-size: 1.14em; color: #999b9d">MIT 概率公开课</a> <a href="/tags/Matery%E4%B8%BB%E9%A2%98/" style="font-size: 1.1em; color: #999">Matery主题</a> <a href="/tags/Matrix-Methods-in-Data-Analysis-Signal-Processing-and-Machine-Learning/" style="font-size: 1.19em; color: #999da1">Matrix Methods in Data Analysis Signal Processing and Machine Learning</a> <a href="/tags/Michael-Collins-NLP/" style="font-size: 1.37em; color: #99a4b2">Michael Collins NLP</a> <a href="/tags/Neural-Network/" style="font-size: 1.34em; color: #99a3b0">Neural Network</a> <a href="/tags/Performance-Engineering-of-Software-Systems/" style="font-size: 1.17em; color: #999c9f">Performance Engineering of Software Systems</a> <a href="/tags/Python%E4%BD%9C%E5%9B%BE/" style="font-size: 1.12em; color: #999a9b">Python作图</a> <a href="/tags/Restricted-Boltzmann-Machines/" style="font-size: 1.1em; color: #999">Restricted Boltzmann Machines</a> <a href="/tags/Scipy/" style="font-size: 1.1em; color: #999">Scipy</a> <a href="/tags/TensorFlow/" style="font-size: 1.1em; color: #999">TensorFlow</a> <a href="/tags/The-Analytics-Edge/" style="font-size: 1.23em; color: #999ea6">The Analytics Edge</a> <a href="/tags/sklearn/" style="font-size: 1.1em; color: #999">sklearn</a> <a href="/tags/t-SNE/" style="font-size: 1.1em; color: #999">t-SNE</a> <a href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 1.37em; color: #99a4b2">信息论</a> <a href="/tags/%E5%85%B7%E4%BD%93%E6%95%B0%E5%AD%A6/" style="font-size: 1.17em; color: #999c9f">具体数学</a> <a href="/tags/%E5%8C%97%E5%A4%A7C-%E6%85%95%E8%AF%BE/" style="font-size: 1.23em; color: #999ea6">北大C++慕课</a> <a href="/tags/%E5%8C%97%E7%90%86Python%E7%88%AC%E8%99%ABmooc/" style="font-size: 1.17em; color: #999c9f">北理Python爬虫mooc</a> <a href="/tags/%E5%9B%BD%E9%98%B2%E7%A7%91%E6%8A%80%E5%A4%A7%E5%AD%A6%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" style="font-size: 1.32em; color: #99a2ae">国防科技大学编译原理</a> <a href="/tags/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3/" style="font-size: 1.12em; color: #999a9b">奇异值分解</a> <a href="/tags/%E5%AE%9E%E5%88%86%E6%9E%90/" style="font-size: 1.41em; color: #99a5b7">实分析</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">21</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">22</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">18</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">二月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">一月 2021</span><span class="card-archive-list-count">15</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/12/"><span class="card-archive-list-date">十二月 2020</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">十一月 2020</span><span class="card-archive-list-count">9</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">610</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-06-07T16:56:53.354Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Doraemonzzz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>