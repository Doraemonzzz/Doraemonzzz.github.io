<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Doraemonzzz - Learn For Fun</title><meta name="author" content="Doraemonzzz"><meta name="copyright" content="Doraemonzzz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="Doraemonzzz">
<meta property="og:url" content="http://www.doraemonzzz.com/page/41/index.html">
<meta property="og:site_name" content="Doraemonzzz">
<meta property="og:description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true">
<meta property="article:author" content="Doraemonzzz">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true"><link rel="shortcut icon" href="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true"><link rel="canonical" href="http://www.doraemonzzz.com/page/41/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6f00f37f957f0608abb8c571105456f0";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-G-RE4B1LKRZD"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-G-RE4B1LKRZD');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"距离上次更新已经","messageNext":"天了，文章内容可能已经过时。"},
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Doraemonzzz',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-08-28 22:43:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/bilibili.css" media="defer" onload="this.media='all'"><meta name="google-site-verification" content="c4v-NmuUZRgl3cvtg9GKswryK1YLaPztd_5M-df5VNI" /><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Doraemonzzz" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src= "/img/loading.gif" data-lazy-src="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">649</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">67</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-chart-pie"></i><span> 博客统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw far fa-chart-bar"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-area"></i><span> 访问统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/top/"><i class="fa-fw fab fa-hotjar"></i><span> 阅读排行榜</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/h3.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Doraemonzzz</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-chart-pie"></i><span> 博客统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw far fa-chart-bar"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-area"></i><span> 访问统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/top/"><i class="fa-fw fab fa-hotjar"></i><span> 阅读排行榜</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Doraemonzzz</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/291079982" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/11/Michael%20Collins%20NLP%20Lecture%205/" title="Michael Collins NLP Lecture 5">Michael Collins NLP Lecture 5</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-11T07:32:00.000Z" title="发表于 2019-02-11 15:32:00">2019-02-11</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-04-14T06:48:21.105Z" title="更新于 2020-04-14 14:48:21">2020-04-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Michael-Collins-NLP/">Michael Collins NLP</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">4.7k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>19分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/11/Michael%20Collins%20NLP%20Lecture%205/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/11/Michael%20Collins%20NLP%20Lecture%205/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程主页：http://www.cs.columbia.edu/~cs4705/
课程网盘地址：
链接：https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3 
这一讲主要介绍了概率上下文无关文法(Probabilistic Context-Free Grammars (PCFGs))。

3.概率上下文无关文法(Probabilistic Context-Free Grammars (PCFGs))3.1 基本定义给定上下文无关文法$G$，我们将使用以下定义：

$\mathcal T_G $是语法$G$下所有可能的最左派生（解析树）的集合。当语法$G$在上下文中很清楚时，我们通常将其简写为$\mathcal T $。

对于任何派生$t\in \mathcal T_G $，我们用$\text{yield}(t)$来表示由$t$的产生的字符串$s\in \Sigma’$（即，$\text{yield}(t)$是$t$中的单词序列）。

对于给定的句子$s\in \Sigma’$，我们用$\mathcal T_G(s)$表示集合
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/10/CS231%20%E7%AC%AC%E4%B9%9D%E8%AE%B2%20CNN%E6%9E%B6%E6%9E%84/" title="CS231 第九讲 CNN架构">CS231 第九讲 CNN架构</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-10T10:07:00.000Z" title="发表于 2019-02-10 18:07:00">2019-02-10</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-12T13:09:59.833Z" title="更新于 2019-02-12 21:09:59">2019-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS231/">CS231</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">531</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/10/CS231%20%E7%AC%AC%E4%B9%9D%E8%AE%B2%20CNN%E6%9E%B6%E6%9E%84/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/10/CS231%20%E7%AC%AC%E4%B9%9D%E8%AE%B2%20CNN%E6%9E%B6%E6%9E%84/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲介绍了一些CNN架构。

AlexNet第一个例子是AlexNet，其架构如下

上图中每一层拆成两部分是因为当时内存不够的原因。
VGGNetVGGNet相比AlexNet来说层数更多，其网络架构如下


GoogLeNetGoogLeNet考虑到计算的问题，利用Inception模块减少了很多参数，Inception模块是一个局部网络，GoogLeNet将很多个Inception模块组成一个大网络，其架构如下

每个Inception模块中进行了并行滤波操作，例如进行多个卷积操作以及池化操作

这样做有一个问题，就是参数会非常多，我们来看个具体例子

从上图中可以看出，如果利用之前所述的架构，那么每个Inception模块计算量就会很大。该问题的解决方案是首先利用$1\times 1$卷积核降低深度，效果如下

在实际中，还用了池化操作，优化后的网络结构如下

利用上述操作减少了大量参数 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/10/CS231%20%E7%AC%AC%E5%85%AB%E8%AE%B2%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%AF%E4%BB%B6/" title="CS231 第八讲 深度学习软件">CS231 第八讲 深度学习软件</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-10T09:13:00.000Z" title="发表于 2019-02-10 17:13:00">2019-02-10</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-12T13:10:04.485Z" title="更新于 2019-02-12 21:10:04">2019-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS231/">CS231</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">196</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/10/CS231%20%E7%AC%AC%E5%85%AB%E8%AE%B2%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%AF%E4%BB%B6/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/10/CS231%20%E7%AC%AC%E5%85%AB%E8%AE%B2%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%AF%E4%BB%B6/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲介绍了PyTorch和TensorFlow。

PyTorch和TensorFlow最主要的区别在于PyTorch建立的是动态图，而TensorFlow建立的是静态图：

静态图的特点是我们只建立一次图，然后不断复用，我们使用的框架会在运行之前优化计算图：

静态图另一个特点只要建立了图，就相当于构造了一个数据结构，可以将其保存下来，很方便的部署（不需要源代码），而动态图则需要保存代码。
不过在条件语句以及循环语句中，由于动态图使用的是语言本身的条件和循环语句，此时会方便很多：


</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/10/CS231%20%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89/" title="CS231 第七讲 训练神经网络（下）">CS231 第七讲 训练神经网络（下）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-10T06:37:00.000Z" title="发表于 2019-02-10 14:37:00">2019-02-10</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-03-15T03:26:52.345Z" title="更新于 2019-03-15 11:26:52">2019-03-15</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS231/">CS231</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.7k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>7分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/10/CS231%20%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/10/CS231%20%E7%AC%AC%E4%B8%83%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8B%EF%BC%89/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲继续介绍训练神经网络的一些技巧。

更好的优化之前我们介绍了随机梯度下降法，但是这个方法有一些问题——如果损失在某个方向降低很快，另一个方向降低很慢，那么图像如下

如果从红点出发，利用随机梯度下降法产生的结果非常震荡，这就会严重影响效率

另一个问题是，随机梯度下降很容易陷入局部最优点和马鞍点

还有一个问题是，随机梯度下降法很容易受到噪声干扰，这会让优化速度减慢

下面介绍几种处理上述问题的优化方法。
Momentum第一种方法是Momentum，其更新公式如下

\begin{aligned}
v_{t+1} &= \rho v_t + \nabla f(x_t) \\
x_{t+1}&= x_t -\alpha v_{t+1}
\end{aligned}伪代码如下
vx = 0
while True:
    dx = compute_gradient(x)
    vx = rho ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/10/Michael%20Collins%20NLP%20Lecture%204/" title="Michael Collins NLP Lecture 4">Michael Collins NLP Lecture 4</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-10T05:19:00.000Z" title="发表于 2019-02-10 13:19:00">2019-02-10</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-04-14T05:54:14.308Z" title="更新于 2020-04-14 13:54:14">2020-04-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Michael-Collins-NLP/">Michael Collins NLP</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.6k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>5分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/10/Michael%20Collins%20NLP%20Lecture%204/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/10/Michael%20Collins%20NLP%20Lecture%204/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程主页：http://www.cs.columbia.edu/~cs4705/
课程网盘地址：
链接：https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3 
这一讲主要介绍了语法解析(Parsing)以及上下文无关法(Context-Free Grammars)。

Chapter 3 概率上下文无关法(Probabilistic Context-Free Grammars (PCFGs))首先介绍语法解析问题，问题形式如下

语法解析的一个应用是机器翻译，因为不同语言中的语法有所不同，例如

本章介绍的概率上下文无关法为处理语法解析问题的一个常用方法，在此之前，我们先介绍上下文无关法(Context-Free Grammars)。
1.上下文无关法(Context-Free Grammars)1.1 基本定义上下文无关法(CFG)是一个四元组$G=(N,\Sigma,R,S)$，其中

$N$是一组有限的非终止符。
$\Sigma$一组有限的终止符。
$R$是形如$X\to Y_1Y_2…Y_n$的有限规则的集合，其中$X\ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/04/Michael%20Collins%20NLP%20Lecture%203/" title="Michael Collins NLP Lecture 3">Michael Collins NLP Lecture 3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-04T09:06:00.000Z" title="发表于 2019-02-04 17:06:00">2019-02-04</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-05-16T07:36:14.674Z" title="更新于 2020-05-16 15:36:14">2020-05-16</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Michael-Collins-NLP/">Michael Collins NLP</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">9.9k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>38分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/04/Michael%20Collins%20NLP%20Lecture%203/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/04/Michael%20Collins%20NLP%20Lecture%203/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程主页：http://www.cs.columbia.edu/~cs4705/
课程网盘地址：
链接：https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3 
这一讲主要介绍了标注问题和隐马尔可夫模型。

Chapter 2 标注问题和隐马尔可夫模型2.1 介绍在许多NLP问题中，我们希望对序列对进行建模。词性（POS）标注可能是此类问题中最早，最著名的例子。 在POS标注中，我们的目标是建立一个模型，其输入为句子，例如

\text{the dog saw a cat}其输出是标注序列

\begin{eqnarray*}
\text{D N V D N}\tag{2.1} 
\end{eqnarray*}（这里我们使用D表示定冠词，N表示名词，V表示动词）。标签序列与输入句子的长度相同，因此为句子中的每个单词指定一个标签（在本例中D标注the，N标注dog，V标注saw，依此类推）。
​    我们将使用$x_1…x_n$来表示标注模型的输入：将其称为句子。在上面的例子中，我们的长度为$n=5$并且

x_1 =\text{ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2022%20Radon%E6%B5%8B%E5%BA%A6%E4%B9%8B%E5%BE%AE%E5%88%86/" title="台大实分析单元 22 Radon测度之微分">台大实分析单元 22 Radon测度之微分</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-04T05:30:00.000Z" title="发表于 2019-02-04 13:30:00">2019-02-04</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-13T09:04:21.559Z" title="更新于 2019-02-13 17:04:21">2019-02-13</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AE%9E%E5%88%86%E6%9E%90/">实分析</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">57</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2022%20Radon%E6%B5%8B%E5%BA%A6%E4%B9%8B%E5%BE%AE%E5%88%86/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2022%20Radon%E6%B5%8B%E5%BA%A6%E4%B9%8B%E5%BE%AE%E5%88%86/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">然后介绍Radon导数的性质。

$\mu$是定义在$\Omega\subset \mathbb R^n$上的Radon测度（$\Omega$为开集），定义

\underline D \mu(x)=\underset {\Omega\supset B\to x}{\lim \inf} \frac {\mu(B)}{\lambda^n (B)}
=\lim_{\delta\to 0^+} \{\inf _{\delta B</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2021%20Riemann%20%E4%B8%8E%20Lebesgue%20%E7%A7%AF%E5%88%86%EF%BC%882%EF%BC%89/" title="台大实分析单元 21 Riemann 与 Lebesgue 积分（2）">台大实分析单元 21 Riemann 与 Lebesgue 积分（2）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-04T05:28:00.000Z" title="发表于 2019-02-04 13:28:00">2019-02-04</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-12T13:10:39.461Z" title="更新于 2019-02-12 21:10:39">2019-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%AE%9E%E5%88%86%E6%9E%90/">实分析</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">889</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>4分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2021%20Riemann%20%E4%B8%8E%20Lebesgue%20%E7%A7%AF%E5%88%86%EF%BC%882%EF%BC%89/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/04/%E5%8F%B0%E5%A4%A7%E5%AE%9E%E5%88%86%E6%9E%90%E5%8D%95%E5%85%83%2021%20Riemann%20%E4%B8%8E%20Lebesgue%20%E7%A7%AF%E5%88%86%EF%BC%882%EF%BC%89/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这一部分继续介绍Riemann积分和Lebesgue积分的关系，然后介绍Radon测度的导数。

Theorem 1
f在I上黎曼可积当且仅当在I上几乎处处连续证明：假设$f$在$I$上黎曼可积，那么

\int_I \underline  f d\lambda^n=\underline \int_I f =\overline \int_I f
 =\int_I \overline f d\lambda^n所以

\int_I (\bar f -\underline  f ) d\lambda^n =0因为$\bar f \ge \underline f$，所以在$I$上

\bar f =\underline f\ \ (a.e)即在$I$上

\bar f =f=\underline f\ \ (a.e)因此$f$在$I$上几乎处处连续。
反之，如果$f$在$I$上几乎处处连续，那么在$I$上

\bar f =f=\underline f\ \ (a.e)因此

\underline \int_I f =\int_I \underline  f d\lambda^n
 =\int ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/02/CS231%20%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89/" title="CS231 第六讲 训练神经网络（上）">CS231 第六讲 训练神经网络（上）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-02T14:21:00.000Z" title="发表于 2019-02-02 22:21:00">2019-02-02</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-12T13:10:48.513Z" title="更新于 2019-02-12 21:10:48">2019-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS231/">CS231</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.3k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>4分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/02/CS231%20%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/02/CS231%20%E7%AC%AC%E5%85%AD%E8%AE%B2%20%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%8A%EF%BC%89/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲主要介绍训练神经网络的一些技巧。

激活函数回顾神经元的架构

我们首先进行线性运算，接着使用激活函数$f$，常用激活函数如下

下面分别介绍这几个激活函数。
Sigmoid
Sigmoid函数有如下三个问题：

1.饱和的神经元会使得梯度消失。
这是因为当$x$绝对值很大时，Sigmoid函数的导数几乎为$0$（这点从图像中就能看出），而这会使训练过程很缓慢。

2.Sigmoid函数输出结果的均值不是$0$。
由于Sigmoid函数输出结果都大于$0$，由乘法门的含义可知，这会导致梯度的符号都相同，这也不利于训练。

3.$\exp()$有一定的计算量。
这个算是比较次要的原因，感觉主要是和之后的ReLU作对比。


tanh
tanh函数可以克服上述第2个问题，因为输出结果的均值为$0$，但是问题1,3依然没有解决。
ReLU
ReLU函数可以有效克服问题1，但是输出结果的均值不是$0 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/02/01/CS229%20Lesson%201%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/" title="CS229 Lesson 1 机器学习的动机与应用">CS229 Lesson 1 机器学习的动机与应用</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-02-01T14:36:00.000Z" title="发表于 2019-02-01 22:36:00">2019-02-01</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-12T13:10:59.874Z" title="更新于 2019-02-12 21:10:59">2019-02-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS229/">CS229</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">483</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/02/01/CS229%20Lesson%201%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/02/01/CS229%20Lesson%201%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8A%A8%E6%9C%BA%E4%B8%8E%E5%BA%94%E7%94%A8/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：http://open.163.com/special/opencourse/machinelearning.html
课程主页：http://cs229.stanford.edu/
更具体的资料链接：https://www.jianshu.com/p/0a6ef31ff77a
笔记参考自中文翻译版：https://github.com/Kivy-CN/Stanford-CS-229-CN
整理完9到20讲之后开始回过头来整理前面8讲，第一讲主要对机器学习做了简介。

监督式学习让我们首先谈谈监督学习问题的几个例子。假设我们有一个数据集，给出了俄勒冈州波特兰市47所房屋的房间大小和价格：

​    作图可得：

​    根据这样的数据，我们如何根据房间大小来学习预测波特兰其他房屋的价格？
​    我们将使用$x^{(i)}$来表示“输入”变量（这个例子中为房间大小），也称为输入特征，$y^{(i)}$表示“输出”或我们正试图预测的目标变量（此处为价格）。 一对$(x^{(i)},y^{(i)})$被称为训练样本，我们将用于学习的数据集——$m$个训练样本$\{(x^ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/01/31/CS231%20%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="CS231 第五讲 卷积神经网络">CS231 第五讲 卷积神经网络</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-01-31T14:42:00.000Z" title="发表于 2019-01-31 22:42:00">2019-01-31</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-02-27T05:52:25.830Z" title="更新于 2019-02-27 13:52:25">2019-02-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/CS231/">CS231</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.2k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>3分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/01/31/CS231%20%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/01/31/CS231%20%E7%AC%AC%E4%BA%94%E8%AE%B2%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">课程视频地址：https://study.163.com/courses-search?keyword=CS231
课程主页：http://cs231n.stanford.edu/2017/
这一讲主要介绍卷积神经网络。

第一部分是介绍历史，这里略过，直接进入正题。
卷积神经网络卷积神经网络主要用于计算机视觉领域，处理对象为图片，首先来比较卷积神经网络和之前介绍的神经网络的区别。
之前介绍的神经网络每层被称为全连接层，形式如下

而卷积神经网络有卷积层，形式如下

那么为什么要使用卷积层而不是全连接层呢？主要如下两个原因。第一个原因是全连接层的权重太多，例如$200\times 200\times 3$的图像将有$120,000$个权重，这很容易导致过拟合（参数太多）以及计算成本太大；第二个原因是图像中有很多模式重复出现，例如边缘等等，使用滤波器可以复用这些共同特征。
下面详细介绍卷积层。
卷积层下面假设图像的维度为$W_1 \times H_1 \times D_1​$，一般来说，滤波器前两个维度相等，而第三个维度必须等于图像的第三个维度，从而这里假设滤波器的维度为$F\times ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2019/01/31/Hexo%E5%8D%9A%E5%AE%A2deploy%E6%8A%A5%E9%94%99/" title="Hexo博客deploy报错">Hexo博客deploy报错</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-01-31T14:25:28.000Z" title="发表于 2019-01-31 22:25:28">2019-01-31</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-04-30T13:24:03.710Z" title="更新于 2019-04-30 21:24:03">2019-04-30</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hexo/">Hexo</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Hexo%E5%8D%9A%E5%AE%A2%E6%8A%A5%E9%94%99/">Hexo博客报错</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">114</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2019/01/31/Hexo%E5%8D%9A%E5%AE%A2deploy%E6%8A%A5%E9%94%99/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2019/01/31/Hexo%E5%8D%9A%E5%AE%A2deploy%E6%8A%A5%E9%94%99/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">今天hexo写博客的时候又遇到一个坑，这里简单记录下。

出现的问题是hexo d之后有如下报错：
Template render error: (unknown path) [Line 147, Column 121]
  expected variable end
网上查了下，发现原因是因为出现了如下形式的连续两个大括号：
&#123;&#123; ,&#125;&#125;
发现问题后，我让大括号之间带个空格，即使用：
&#123; &#123; ,&#125; &#125;
替换上述符号，果然解决了。
</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/40/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/40/#content-inner">40</a><span class="page-number current">41</span><a class="page-number" href="/page/42/#content-inner">42</a><span class="space">&hellip;</span><a class="page-number" href="/page/55/#content-inner">55</a><a class="extend next" rel="next" href="/page/42/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src= "/img/loading.gif" data-lazy-src="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Doraemonzzz</div><div class="author-info__description">个人博客，主要记录有关机器学习，数学以及计算机科学的笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">649</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">67</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Doraemonzzz"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/291079982" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">暂无公告</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/08/28/2021-8-28-CMU-15-213-Lab5-Shell-Lab/" title="CMU 15-213 Lab5 Shell Lab"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CMU 15-213 Lab5 Shell Lab"/></a><div class="content"><a class="title" href="/2021/08/28/2021-8-28-CMU-15-213-Lab5-Shell-Lab/" title="CMU 15-213 Lab5 Shell Lab">CMU 15-213 Lab5 Shell Lab</a><time datetime="2021-08-28T14:14:00.000Z" title="发表于 2021-08-28 22:14:00">2021-08-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/28/2021-8-28-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-4-Continued-fractions/" title="计算机程序的构造和解释(SICP) Assignment 4 Continued fractions"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机程序的构造和解释(SICP) Assignment 4 Continued fractions"/></a><div class="content"><a class="title" href="/2021/08/28/2021-8-28-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-4-Continued-fractions/" title="计算机程序的构造和解释(SICP) Assignment 4 Continued fractions">计算机程序的构造和解释(SICP) Assignment 4 Continued fractions</a><time datetime="2021-08-27T17:02:00.000Z" title="发表于 2021-08-28 01:02:00">2021-08-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/28/2021-8-28-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-3-Graphing-with-higher-order-procedures/" title="计算机程序的构造和解释(SICP) Assignment 3 Graphing with higher-order procedures"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机程序的构造和解释(SICP) Assignment 3 Graphing with higher-order procedures"/></a><div class="content"><a class="title" href="/2021/08/28/2021-8-28-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-3-Graphing-with-higher-order-procedures/" title="计算机程序的构造和解释(SICP) Assignment 3 Graphing with higher-order procedures">计算机程序的构造和解释(SICP) Assignment 3 Graphing with higher-order procedures</a><time datetime="2021-08-27T16:09:00.000Z" title="发表于 2021-08-28 00:09:00">2021-08-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/27/2021-8-27-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-2-The-game-of-twenty-one/" title="计算机程序的构造和解释(SICP) Assignment 2 The game of twenty-one"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机程序的构造和解释(SICP) Assignment 2 The game of twenty-one"/></a><div class="content"><a class="title" href="/2021/08/27/2021-8-27-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-2-The-game-of-twenty-one/" title="计算机程序的构造和解释(SICP) Assignment 2 The game of twenty-one">计算机程序的构造和解释(SICP) Assignment 2 The game of twenty-one</a><time datetime="2021-08-27T15:49:00.000Z" title="发表于 2021-08-27 23:49:00">2021-08-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/27/2021-8-27-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-1-Introductory-assignment/" title="计算机程序的构造和解释(SICP) Assignment 1 Introductory assignment"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机程序的构造和解释(SICP) Assignment 1 Introductory assignment"/></a><div class="content"><a class="title" href="/2021/08/27/2021-8-27-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A(SICP)-Assignment-1-Introductory-assignment/" title="计算机程序的构造和解释(SICP) Assignment 1 Introductory assignment">计算机程序的构造和解释(SICP) Assignment 1 Introductory assignment</a><time datetime="2021-08-27T14:53:00.000Z" title="发表于 2021-08-27 22:53:00">2021-08-27</time></div></div></div></div><div class="card-widget" id="card-newest-comments"><div class="item-headline"><i class="fas fa-bolt"></i><span>最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI/"><span class="card-category-list-name">AI</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C/"><span class="card-category-list-name">C++</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C%E8%AF%AD%E8%A8%80/"><span class="card-category-list-name">C语言</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo/"><span class="card-category-list-name">Hexo</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/JAVA/"><span class="card-category-list-name">JAVA</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">48</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python%E7%88%AC%E8%99%AB/"><span class="card-category-list-name">Python爬虫</span><span class="card-category-list-count">5</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Matrix-Methods-in-Data-Analysis-Signal-Processing-and-Machine-Learning/" style="font-size: 1.21em; color: rgb(68, 2, 120)">Matrix Methods in Data Analysis Signal Processing and Machine Learning</a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A/" style="font-size: 1.45em; color: rgb(106, 6, 120)">计算机程序的构造和解释</a><a href="/tags/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" style="font-size: 1.39em; color: rgb(65, 126, 131)">斯坦福大学编译原理</a><a href="/tags/CS170/" style="font-size: 1.37em; color: rgb(190, 51, 176)">CS170</a><a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 1.23em; color: rgb(133, 45, 88)">杂谈</a><a href="/tags/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/" style="font-size: 1.18em; color: rgb(184, 96, 101)">博客配置</a><a href="/tags/Socket-Programming/" style="font-size: 1.18em; color: rgb(53, 55, 2)">Socket Programming</a><a href="/tags/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/" style="font-size: 1.31em; color: rgb(161, 166, 19)">深入理解计算机系统</a><a href="/tags/%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA/" style="font-size: 1.18em; color: rgb(42, 85, 14)">算法概论</a><a href="/tags/Wireshark-Lab/" style="font-size: 1.17em; color: rgb(35, 100, 22)">Wireshark Lab</a><a href="/tags/Python%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 1.15em; color: rgb(7, 75, 58)">Python小技巧</a><a href="/tags/6-S081/" style="font-size: 1.17em; color: rgb(41, 69, 78)">6.S081</a><a href="/tags/transformer%E4%BC%98%E5%8C%96/" style="font-size: 1.15em; color: rgb(4, 150, 74)">transformer优化</a><a href="/tags/Flarum/" style="font-size: 1.17em; color: rgb(189, 200, 37)">Flarum</a><a href="/tags/pytorch/" style="font-size: 1.15em; color: rgb(146, 106, 129)">pytorch</a><a href="/tags/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" style="font-size: 1.18em; color: rgb(129, 103, 23)">算法分析</a><a href="/tags/CMU-15-213/" style="font-size: 1.36em; color: rgb(57, 139, 66)">CMU 15-213</a><a href="/tags/CS205A/" style="font-size: 1.37em; color: rgb(129, 5, 154)">CS205A</a><a href="/tags/CS224N/" style="font-size: 1.34em; color: rgb(193, 194, 64)">CS224N</a><a href="/tags/CS229/" style="font-size: 1.42em; color: rgb(25, 12, 124)">CS229</a><a href="/tags/CS231/" style="font-size: 1.32em; color: rgb(31, 90, 63)">CS231</a><a href="/tags/CS234-Reinforcement-Learning/" style="font-size: 1.15em; color: rgb(52, 107, 168)">CS234 Reinforcement Learning</a><a href="/tags/CS236-Deep-Generative-Models/" style="font-size: 1.26em; color: rgb(177, 62, 174)">CS236 Deep Generative Models</a><a href="/tags/CS50/" style="font-size: 1.24em; color: rgb(126, 110, 63)">CS50</a><a href="/tags/%E5%8C%97%E5%A4%A7C-%E6%85%95%E8%AF%BE/" style="font-size: 1.24em; color: rgb(109, 105, 177)">北大C++慕课</a><a href="/tags/David-silver-Reinforcement-Learning/" style="font-size: 1.29em; color: rgb(45, 138, 11)">David silver Reinforcement Learning</a><a href="/tags/DLHLP/" style="font-size: 1.24em; color: rgb(176, 3, 144)">DLHLP</a><a href="/tags/DSP/" style="font-size: 1.28em; color: rgb(75, 124, 8)">DSP</a><a href="/tags/%E8%8A%AF%E7%89%87%E8%AE%BE%E8%AE%A1/" style="font-size: 1.18em; color: rgb(175, 148, 70)">芯片设计</a><a href="/tags/EE261/" style="font-size: 1.43em; color: rgb(188, 90, 111)">EE261</a><a href="/tags/EE263/" style="font-size: 1.4em; color: rgb(44, 182, 11)">EE263</a><a href="/tags/EE364A/" style="font-size: 1.23em; color: rgb(116, 137, 14)">EE364A</a><a href="/tags/From-Nand-to-Tetris/" style="font-size: 1.28em; color: rgb(77, 75, 168)">From Nand to Tetris</a><a href="/tags/Hexo%E5%8D%9A%E5%AE%A2%E6%8A%A5%E9%94%99/" style="font-size: 1.21em; color: rgb(184, 77, 161)">Hexo博客报错</a><a href="/tags/Matery%E4%B8%BB%E9%A2%98/" style="font-size: 1.15em; color: rgb(132, 155, 135)">Matery主题</a><a href="/tags/Hoeffding%E4%B8%8D%E7%AD%89%E5%BC%8F/" style="font-size: 1.15em; color: rgb(10, 12, 111)">Hoeffding不等式</a><a href="/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/" style="font-size: 1.32em; color: rgb(67, 189, 89)">信息论</a><a href="/tags/Advanced-Machine-Learning/" style="font-size: 1.2em; color: rgb(46, 132, 153)">Advanced Machine Learning</a><a href="/tags/Performance-Engineering-of-Software-Systems/" style="font-size: 1.2em; color: rgb(61, 198, 95)">Performance Engineering of Software Systems</a><a href="/tags/Michael-Collins-NLP/" style="font-size: 1.32em; color: rgb(28, 103, 178)">Michael Collins NLP</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">17</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">五月 2021</span><span class="card-archive-list-count">21</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/04/"><span class="card-archive-list-date">四月 2021</span><span class="card-archive-list-count">22</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/03/"><span class="card-archive-list-date">三月 2021</span><span class="card-archive-list-count">18</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/02/"><span class="card-archive-list-date">二月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/01/"><span class="card-archive-list-date">一月 2021</span><span class="card-archive-list-count">15</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">649</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2018-03-09T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">1040.5k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-08-28T14:43:35.693Z"></div></div></div></div><div class="card-widget user-map" id="user-map" style="order: 3"><div class="item-headline"><i class="fas fa-heartbeat"></i><span>访客地图</span></div><div class="item-content"><script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=q1NruxJWhX9RKKuuAGRqK9PyMZ1xNURePPrNM8SEbR4"></script></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2021 By Doraemonzzz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(() => {
  function loadValine () {
    function initValine () {
      let initData = {
        el: '#vcomment',
        appId: 'IpnmxCW9CvYWIXbol5QXsegX-MdYXbMMI',
        appKey: 'w57DVCdbxcyB1TYYagMIMJIU',
      }
      
      const valine = new Valine(initData)
    }

    if (typeof Valine === 'function') initValine() 
    else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
  }

  window.pjax ? loadValine() : window.addEventListener('load', loadValine)
})()</script></div><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.17.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=monsterid'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://IpnmxCW9.api.lncldglobal.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'IpnmxCW9CvYWIXbol5QXsegX-MdYXbMMI',
        "X-LC-Key": 'w57DVCdbxcyB1TYYagMIMJIU',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>