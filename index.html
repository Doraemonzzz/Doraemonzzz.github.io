<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Doraemonzzz - Learn For Fun</title><meta name="author" content="Doraemonzzz"><meta name="copyright" content="Doraemonzzz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:type" content="website">
<meta property="og:title" content="Doraemonzzz">
<meta property="og:url" content="http://www.doraemonzzz.com/index.html">
<meta property="og:site_name" content="Doraemonzzz">
<meta property="og:description" content="个人博客，主要记录有关机器学习，数学以及计算机科学的笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true">
<meta property="article:author" content="Doraemonzzz">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true"><link rel="shortcut icon" href="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true"><link rel="canonical" href="http://www.doraemonzzz.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6f00f37f957f0608abb8c571105456f0";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-G-RE4B1LKRZD"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-G-RE4B1LKRZD');
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"距离上次更新已经","messageNext":"天了，文章内容可能已经过时。"},
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Doraemonzzz',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-02-02 23:48:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/bilibili.css" media="defer" onload="this.media='all'"><meta name="google-site-verification" content="c4v-NmuUZRgl3cvtg9GKswryK1YLaPztd_5M-df5VNI" /><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Doraemonzzz" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src= "/img/loading.gif" data-lazy-src="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">796</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">79</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">32</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-chart-pie"></i><span> 博客统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw far fa-chart-bar"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-area"></i><span> 访问统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/top/"><i class="fa-fw fab fa-hotjar"></i><span> 阅读排行榜</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/h3.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Doraemonzzz</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-chart-pie"></i><span> 博客统计</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw far fa-chart-bar"></i><span> 文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-area"></i><span> 访问统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/top/"><i class="fa-fw fab fa-hotjar"></i><span> 阅读排行榜</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Doraemonzzz</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/291079982" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2018/07/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B1%87%E6%80%BB%E5%B8%96/" title="机器学习以及计算机公开课汇总帖">机器学习以及计算机公开课汇总帖</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-07-01T10:34:00.000Z" title="发表于 2018-07-01 18:34:00">2018-07-01</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-12T01:35:09.759Z" title="更新于 2021-06-12 09:35:09">2021-06-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9D%82%E8%B0%88/">杂谈</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">2.7k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>9分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2018/07/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B1%87%E6%80%BB%E5%B8%96/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2018/07/01/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%85%AC%E5%BC%80%E8%AF%BE%E6%B1%87%E6%80%BB%E5%B8%96/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">之前在简书上发过两个帖子，分别总结了CS以及机器学习的课程资源，现在也学习了几个月，就把学完的记录在这里，部分课程做了笔记的也会列出。
系统自学计算机课程：
https://www.jianshu.com/p/8f2646a825e8
机器学习资料：
https://www.jianshu.com/p/dc9020fd03b1

计算机计算机基础
哈佛大学 CS50
https://www.edx.org/course/cs50s-introduction-computer-science-harvardx-cs50x
如果0基础想要学习计算机知识，非常推荐这门课，课程生动有趣。这门课面非常广，介绍了C语言，SQL，HTML，Python以及Javascript，如果时间有限，可以着重学习C语言部分。

Nand to Tetris
https://www.coursera.org/learn/build-a-computer
https://www.coursera.org/learn/nand2tetris2
https://www.nand2tetris.org/
非常非常好的课 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/04/24/2021-4-24-%E6%9C%AA%E5%AE%8C%E6%88%90%E7%9A%84%E8%AF%BE%E7%A8%8B%E6%B1%87%E6%80%BB/" title="未完成的课程汇总">未完成的课程汇总</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-04-24T14:38:00.000Z" title="发表于 2021-04-24 22:38:00">2021-04-24</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-10-24T15:22:56.514Z" title="更新于 2021-10-24 23:22:56">2021-10-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%9D%82%E8%B0%88/">杂谈</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">163</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/04/24/2021-4-24-%E6%9C%AA%E5%AE%8C%E6%88%90%E7%9A%84%E8%AF%BE%E7%A8%8B%E6%B1%87%E6%80%BB/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/04/24/2021-4-24-%E6%9C%AA%E5%AE%8C%E6%88%90%E7%9A%84%E8%AF%BE%E7%A8%8B%E6%B1%87%E6%80%BB/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">由于时间或者个人原因，在学习的过程中难免有没有学习完的课程，这里会将其列出，方便后续填坑。

未完成列表
MIT 6.172（完成4讲）
MIT 概率课程
台交大信息论（完成10讲）
台交大随机过程（完成6讲）
Information Theory, Inference and Learning Algorithms（完成8讲）
MIT 18.605 Matrix Methods in Data Analysis, Signal Processing, and Machine Learning（上传6讲，完成到21讲）
CS236 Deep Generative Models（完成8讲）
CS234 强化学习（完成1讲）
EE364 凸优化（完成8讲）
Deep Learning for Human Language Processing （完成语音部分）
斯坦福算法专项课程（完成9周内容）

</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/" title="博客主题配置">博客主题配置</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-06-12T01:32:28.000Z" title="发表于 2021-06-12 09:32:28">2021-06-12</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-10-24T03:24:53.453Z" title="更新于 2021-10-24 11:24:53">2021-10-24</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hexo/">Hexo</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/">博客配置</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">5.8k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>29分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">记录博客主题的配置以及相关优化。</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9%E6%95%B4%E7%90%86/" title="博客内容整理">博客内容整理</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-06-12T08:26:28.000Z" title="发表于 2021-06-12 16:26:28">2021-06-12</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-14T13:44:24.380Z" title="更新于 2021-06-14 21:44:24">2021-06-14</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Hexo/">Hexo</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/">博客配置</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">163</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9%E6%95%B4%E7%90%86/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2021/06/12/2021-6-12-%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9%E6%95%B4%E7%90%86/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">记录对博客内容整理的过程。</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/02/02/2023-2-2-ECE408-Lecture-12-Convolutional-Neural-Networks/" title="ECE408 Lecture 12 Convolutional Neural Networks">ECE408 Lecture 12 Convolutional Neural Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-02T09:48:00.000Z" title="发表于 2023-02-02 17:48:00">2023-02-02</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-02T15:47:01.399Z" title="更新于 2023-02-02 23:47:01">2023-02-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Cuda/">Cuda</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ECE408/">ECE408</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">2.2k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>9分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/02/02/2023-2-2-ECE408-Lecture-12-Convolutional-Neural-Networks/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/02/02/2023-2-2-ECE408-Lecture-12-Convolutional-Neural-Networks/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这次回顾ECE408 Lecture 12，这次介绍了卷积神经网络。
课程主页：

https://wiki.illinois.edu/wiki/display/ECE408

搬运视频：

https://www.youtube.com/playlist?list=PL6RdenZrxrw-UKfRL5smPfFFpeqwN3Dsz


卷积层剖析输入：

$A$个形状为$N_1\times N_1$；

卷积层：

$B$个形状为$K_1\times K_2$的卷积核；

输出：

$A\times B$个输出，形状为$(N_1-K_1+1)\times (N_2-K_2+1)$；


Pooling(降采样)
降采样层
有时内置偏差和非线性；


常见类型
最大值、平均值、L2 范数、加权平均值；


有助于使表示对输入中的大小缩放和平移保持不变；


卷积前向传播
序列版本的代码void convLayer_forward(int B, int M, int C, int H, int W, int K, float* X, float* W, float* Y) &#123; ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/02/02/2023-2-2-ECE408-Lecture-11-Feed-Forward-Networks-and-Gradient-Based-Training/" title="ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training">ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-02T08:59:00.000Z" title="发表于 2023-02-02 16:59:00">2023-02-02</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-02T09:46:42.348Z" title="更新于 2023-02-02 17:46:42">2023-02-02</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Cuda/">Cuda</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ECE408/">ECE408</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">419</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>1分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/02/02/2023-2-2-ECE408-Lecture-11-Feed-Forward-Networks-and-Gradient-Based-Training/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/02/02/2023-2-2-ECE408-Lecture-11-Feed-Forward-Networks-and-Gradient-Based-Training/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这次回顾ECE408 Lecture 11，这次介绍了前馈神经网络和梯度下降法。
课程主页：

https://wiki.illinois.edu/wiki/display/ECE408

搬运视频：

https://www.youtube.com/playlist?list=PL6RdenZrxrw-UKfRL5smPfFFpeqwN3Dsz


这一章大部分内容都比较熟悉，这里只回顾为什么要使用CNN做图像分类。
用MLP做图像分类考虑一张$250\times 250$的图像：

输入：将二维图像处理为一维向量；
全连接层太大：
每个节点$250^2=62500$个权重！
大约总共有~4B总权重！


如果层数大于1参数就会更多，并且这样的网络无法处理更大的图像；
总的来说，需要太多的计算和内存开销；

图像处理中传统的特征检测使用：

滤波器，卷积核；
我们可以在神经网络中使用它们吗？

2D卷积
MLP和卷积的对比
MLP层有固定的结构，所以输入/输出的数量是固定的；
卷积支持可变大小的输入（对同一事物的观察）
不同长度的音频；
不同像素的图像；




为什么使用卷积
稀疏 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/20/2023-1-20-Deep-Learning-Systems-Lecture-4-Automatic-Differentiation/" title="Deep Learning Systems Lecture 4 Automatic Differentiation">Deep Learning Systems Lecture 4 Automatic Differentiation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-20T08:35:00.000Z" title="发表于 2023-01-20 16:35:00">2023-01-20</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-20T09:15:32.643Z" title="更新于 2023-01-20 17:15:32">2023-01-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/">深度学习系统</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.4k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>6分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/20/2023-1-20-Deep-Learning-Systems-Lecture-4-Automatic-Differentiation/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/20/2023-1-20-Deep-Learning-Systems-Lecture-4-Automatic-Differentiation/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这里回顾dlsys第四讲，本讲内容是自动微分。
课程主页：

https://dlsyscourse.org/
https://forum.dlsyscourse.org/
https://mugrade-online.dlsyscourse.org/


大纲
不同微分方法的介绍；
反向模式自动微分；

不同微分方法的介绍微分在机器学习的那个步骤起作用回顾：每个机器学习算法都包含三个不同的元素。计算关于假设类参数的损失函数梯度是机器学习中最常见的操作：

数值微分数值微分是根据定义直接计算梯度：

\frac{\partial f(\theta)}{\partial \theta_i}=\lim _{\epsilon \rightarrow 0} \frac{f\left(\theta+\epsilon e_i\right)-f(\theta)}{\epsilon}一种更精确的近似梯度的方法：

\frac{\partial f(\theta)}{\partial \theta_i}=\frac{f\left(\theta+\epsilon e_i\right)-f\left(\th ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/19/2023-1-19-ECE408-Lecture-10-Introduction-to-Machine-Learning/" title="ECE408 Lecture 10 Introduction to Machine Learning">ECE408 Lecture 10 Introduction to Machine Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-19T05:32:00.000Z" title="发表于 2023-01-19 13:32:00">2023-01-19</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-19T05:01:06.068Z" title="更新于 2023-01-19 13:01:06">2023-01-19</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Cuda/">Cuda</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ECE408/">ECE408</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">828</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>2分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/19/2023-1-19-ECE408-Lecture-10-Introduction-to-Machine-Learning/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/19/2023-1-19-ECE408-Lecture-10-Introduction-to-Machine-Learning/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这次回顾ECE408 Lecture 10，这次介绍了机器学习。
课程主页：

https://wiki.illinois.edu/wiki/display/ECE408

搬运视频：

https://www.youtube.com/playlist?list=PL6RdenZrxrw-UKfRL5smPfFFpeqwN3Dsz


引子
计算技术的发展是基于这样一个前提，即有一天，计算机器将能够模仿一般的人类智能；
从计算能力的角度来看，摩尔定律推动了智能机器的发展。 硬件速度每18个月提高2倍；
然而，软件方面一直是一个令人烦恼的悬而未决的问题；


用软件解决难题（既定方法）使用传统方法解决问题的思路是从算法包到软件然后到问题：

机器学习重新定义了范式
例子：CNN
机器学习
构建逻辑未被人们完全理解的应用程序；
使用标记数据——带有输入值及其所需输出值的数据——来了解逻辑应该是什么；




机器学习任务
分类
输出属于$k$个类别中的哪一个；
例如：物体识别；


回归
预测给定一些输入的数值；
例如：预测明天的温度；


Transcription  
将非结构化数据转 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/19/2023-1-19-ECE408-Lecture-9-Tiled-Convolution-Analysis/" title="ECE408 Lecture 9 Tiled Convolution Analysis">ECE408 Lecture 9 Tiled Convolution Analysis</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-19T04:32:00.000Z" title="发表于 2023-01-19 12:32:00">2023-01-19</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-20T12:35:54.936Z" title="更新于 2023-01-20 20:35:54">2023-01-20</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Cuda/">Cuda</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/ECE408/">ECE408</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.2k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>5分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/19/2023-1-19-ECE408-Lecture-9-Tiled-Convolution-Analysis/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/19/2023-1-19-ECE408-Lecture-9-Tiled-Convolution-Analysis/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这次回顾ECE408 Lecture 9，这次介绍了分块卷积分析（Tiled Convolution Analysis）。
课程主页：

https://wiki.illinois.edu/wiki/display/ECE408

搬运视频：

https://www.youtube.com/playlist?list=PL6RdenZrxrw-UKfRL5smPfFFpeqwN3Dsz


GPU内存架构
模板模式
数字处理算法根据某种固定模式更新数组元素，称为模板；
卷积只是其中一个例子；

示例：

除此之外，卷积还可以应用于卷积神经网络。
1D卷积

上图是块1的输出和输入块；
第一行为输入，第二行为输出；


对于MASK_WIDTH为5，每个块加载8 + (5 – 1) = 12​个元素（​12个内存加载）；



$P[8]$使用$N[6],N[7],N[8],N[9],N[10]$；
$P[9]$使用$N[7],N[8],N[9],N[10],N[11]$；
……
$P[15]$使用$N[13],N[14],N[15],N[16],N[17]$；
一共8 * 5 = 4 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/18/2023-1-18-Deep-Learning-Systems-Lecture-3-Manual-Neural-Networks-and-Backprop/" title="Deep Learning Systems Lecture 3 Manual Neural Networks and Backprop">Deep Learning Systems Lecture 3 Manual Neural Networks and Backprop</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-18T11:23:00.000Z" title="发表于 2023-01-18 19:23:00">2023-01-18</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-18T12:21:20.021Z" title="更新于 2023-01-18 20:21:20">2023-01-18</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/">深度学习系统</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.1k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>3分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/18/2023-1-18-Deep-Learning-Systems-Lecture-3-Manual-Neural-Networks-and-Backprop/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/18/2023-1-18-Deep-Learning-Systems-Lecture-3-Manual-Neural-Networks-and-Backprop/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这里回顾dlsys第三讲，本讲内容是神经网络和反向传播。
课程主页：

https://dlsyscourse.org/
https://forum.dlsyscourse.org/
https://mugrade-online.dlsyscourse.org/


大纲
从线性到非线性假设类；
神经网络；
反向传播（即计算梯度）；

从线性到非线性假设类线性假设类的问题回想一下，我们需要一个假设函数来将$\mathbb R^n$中的输入映射到$\mathbb R^k$中的输出，因此我们最初使用线性假设类：

h_\theta(x)=\theta^T x, \quad \theta \in \mathbb{R}^{n \times k}这个分类器本质上形成了输入的$k$个线性函数，然后预测值最大的类，相当于把输入分成每个类对应的$k$个线性区域：

非线性分类边界呢？如果我们的数据不能被一组线性区域分开怎么办？我们想要一些方法通过一组非线性的类边界来分离这些点：
一个想法：将线性分类器应用于数据的某些（可能是更高维度的）特征：

\begin{gathered}
h_\theta(x) ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/16/2023-1-16-Deep-Learning-Systems-Lecture-2-ML-Refresher-and-Softmax-Regression/" title="Deep Learning Systems Lecture 2 ML Refresher and Softmax Regression">Deep Learning Systems Lecture 2 ML Refresher and Softmax Regression</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-16T04:12:00.000Z" title="发表于 2023-01-16 12:12:00">2023-01-16</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-16T07:42:13.323Z" title="更新于 2023-01-16 15:42:13">2023-01-16</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/">深度学习系统</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.7k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>7分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/16/2023-1-16-Deep-Learning-Systems-Lecture-2-ML-Refresher-and-Softmax-Regression/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/16/2023-1-16-Deep-Learning-Systems-Lecture-2-ML-Refresher-and-Softmax-Regression/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这里回顾dlsys第二讲，本讲内容是机器学习回顾以及Softmax回归。
课程主页：

https://dlsyscourse.org/
https://forum.dlsyscourse.org/
https://mugrade-online.dlsyscourse.org/


大纲
机器学习基础；
Softmax回归；

机器学习基础机器学习是数据驱动的编程
假设您要编写一个程序，将手写的数字图分类为适当的类别：0,1,…,9；
您可以认真思考数字的性质，尝试确定表示数字类型的逻辑，并编写一个程序来编码此逻辑（尽管我是一个合格的程序员，但我认为我不能很好地做到这一点 )；


一个简单的方式是使用机器学习，特别的，有监督学习：收集一组具有已知标签的图像训练集，并将其输入机器学习算法，该算法（如果做得好）将自动生成解决此任务的“程序”：

机器学习算法的三要素每个机器学习算法都包含三个不同的元素：

假设类：“程序结构”，通过一组参数参数化，描述了我们如何将输入（例如，数字图像）映射到输出（例如，类标签或不同类标签的概率）；
损失函数：指定给定假设（即参数的选择）在感兴趣的任务上执 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/01/15/2023-1-15-Deep-Learning-Systems-Lecture-1-Introduction-and-Logistics/" title="Deep Learning Systems Lecture 1 Introduction and Logistics">Deep Learning Systems Lecture 1 Introduction and Logistics</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-01-15T13:14:00.000Z" title="发表于 2023-01-15 21:14:00">2023-01-15</time><span class="article-meta__separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-01-15T16:04:18.666Z" title="更新于 2023-01-16 00:04:18">2023-01-16</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/">深度学习系统</a></span><span class="article-meta__separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计: </span><span class="word-count">1.1k</span><span class="article-meta__separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长: </span><span>3分钟</span></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-comments"></i><a href="/2023/01/15/2023-1-15-Deep-Learning-Systems-Lecture-1-Introduction-and-Logistics/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2023/01/15/2023-1-15-Deep-Learning-Systems-Lecture-1-Introduction-and-Logistics/" itemprop="commentCount"></span></a><span class="article-meta-label"> 条评论</span></span></div><div class="content">这里回顾dlsys第一讲，本讲内容是课程介绍。
课程主页：

https://dlsyscourse.org/
https://forum.dlsyscourse.org/
https://mugrade-online.dlsyscourse.org/


大纲
为什么要研究深度学习系统？
课程信息和规划；

课程目标
本课程将为您介绍现代深度学习系统的功能；
您将了解现代深度学习系统的基本概念，例如自动微分、神经网络架构、优化以及在GPU等系统上的高效操作；
为了巩固您的理解，在此过程中（在您的家庭作业中），您将构建（从头开始）needle，这是一个与PyTorch松类似的深度学习库，并在该库中实现许多常见的架构；

为什么要研究深度学习系统？为什么学习深度学习？在回答为什么要研究深度学习系统之前，老师首先给出了为什么要学习深度学习的原因？深度学习最近10年来取得惊人的进展，老师这里给出了一些例子：


这些例子大部分都是大机构利用大算力做出来的结果，那么小玩家是否有机会呢？这里老师举了三个例子：

为什么学习深度学习系统？从谷歌趋势可以看出，深度学习越来越流行，其中几个关键点是深度 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/67/#content-inner">67</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src= "/img/loading.gif" data-lazy-src="https://github.com/Doraemonzzz/md-photo/blob/master/%E5%A4%B4%E5%83%8F.jpg?raw=true" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Doraemonzzz</div><div class="author-info__description">个人博客，主要记录有关机器学习，数学以及计算机科学的笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">796</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">79</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">32</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Doraemonzzz"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/291079982" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fa fa-rss"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">暂无公告</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/02/2023-2-2-ECE408-Lecture-12-Convolutional-Neural-Networks/" title="ECE408 Lecture 12 Convolutional Neural Networks"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ECE408 Lecture 12 Convolutional Neural Networks"/></a><div class="content"><a class="title" href="/2023/02/02/2023-2-2-ECE408-Lecture-12-Convolutional-Neural-Networks/" title="ECE408 Lecture 12 Convolutional Neural Networks">ECE408 Lecture 12 Convolutional Neural Networks</a><time datetime="2023-02-02T09:48:00.000Z" title="发表于 2023-02-02 17:48:00">2023-02-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/02/2023-2-2-ECE408-Lecture-11-Feed-Forward-Networks-and-Gradient-Based-Training/" title="ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training"/></a><div class="content"><a class="title" href="/2023/02/02/2023-2-2-ECE408-Lecture-11-Feed-Forward-Networks-and-Gradient-Based-Training/" title="ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training">ECE408 Lecture 11 Feed-Forward Networks and Gradient-Based Training</a><time datetime="2023-02-02T08:59:00.000Z" title="发表于 2023-02-02 16:59:00">2023-02-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/20/2023-1-20-Deep-Learning-Systems-Lecture-4-Automatic-Differentiation/" title="Deep Learning Systems Lecture 4 Automatic Differentiation"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Deep Learning Systems Lecture 4 Automatic Differentiation"/></a><div class="content"><a class="title" href="/2023/01/20/2023-1-20-Deep-Learning-Systems-Lecture-4-Automatic-Differentiation/" title="Deep Learning Systems Lecture 4 Automatic Differentiation">Deep Learning Systems Lecture 4 Automatic Differentiation</a><time datetime="2023-01-20T08:35:00.000Z" title="发表于 2023-01-20 16:35:00">2023-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/19/2023-1-19-ECE408-Lecture-10-Introduction-to-Machine-Learning/" title="ECE408 Lecture 10 Introduction to Machine Learning"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ECE408 Lecture 10 Introduction to Machine Learning"/></a><div class="content"><a class="title" href="/2023/01/19/2023-1-19-ECE408-Lecture-10-Introduction-to-Machine-Learning/" title="ECE408 Lecture 10 Introduction to Machine Learning">ECE408 Lecture 10 Introduction to Machine Learning</a><time datetime="2023-01-19T05:32:00.000Z" title="发表于 2023-01-19 13:32:00">2023-01-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/19/2023-1-19-ECE408-Lecture-9-Tiled-Convolution-Analysis/" title="ECE408 Lecture 9 Tiled Convolution Analysis"><img src= "/img/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ECE408 Lecture 9 Tiled Convolution Analysis"/></a><div class="content"><a class="title" href="/2023/01/19/2023-1-19-ECE408-Lecture-9-Tiled-Convolution-Analysis/" title="ECE408 Lecture 9 Tiled Convolution Analysis">ECE408 Lecture 9 Tiled Convolution Analysis</a><time datetime="2023-01-19T04:32:00.000Z" title="发表于 2023-01-19 12:32:00">2023-01-19</time></div></div></div></div><div class="card-widget" id="card-newest-comments"><div class="item-headline"><i class="fas fa-bolt"></i><span>最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/AI/"><span class="card-category-list-name">AI</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C/"><span class="card-category-list-name">C++</span><span class="card-category-list-count">8</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Cuda/"><span class="card-category-list-name">Cuda</span><span class="card-category-list-count">13</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/C%E8%AF%AD%E8%A8%80/"><span class="card-category-list-name">C语言</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Hexo/"><span class="card-category-list-name">Hexo</span><span class="card-category-list-count">11</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/JAVA/"><span class="card-category-list-name">JAVA</span><span class="card-category-list-count">6</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">48</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">3</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Matrix-Methods-in-Data-Analysis-Signal-Processing-and-Machine-Learning/" style="font-size: 1.22em; color: rgb(188, 110, 19)">Matrix Methods in Data Analysis Signal Processing and Machine Learning</a><a href="/tags/CMU-15-213/" style="font-size: 1.41em; color: rgb(4, 181, 55)">CMU 15-213</a><a href="/tags/transformer%E4%BC%98%E5%8C%96/" style="font-size: 1.18em; color: rgb(115, 49, 51)">transformer优化</a><a href="/tags/attention/" style="font-size: 1.15em; color: rgb(158, 11, 37)">attention</a><a href="/tags/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/" style="font-size: 1.35em; color: rgb(119, 62, 148)">深入理解计算机系统</a><a href="/tags/CS144/" style="font-size: 1.31em; color: rgb(34, 117, 97)">CS144</a><a href="/tags/6-S081/" style="font-size: 1.23em; color: rgb(41, 58, 29)">6.S081</a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9E%84%E9%80%A0%E5%92%8C%E8%A7%A3%E9%87%8A/" style="font-size: 1.45em; color: rgb(97, 67, 187)">计算机程序的构造和解释</a><a href="/tags/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" style="font-size: 1.38em; color: rgb(64, 196, 65)">斯坦福大学编译原理</a><a href="/tags/CS170/" style="font-size: 1.37em; color: rgb(35, 88, 181)">CS170</a><a href="/tags/%E6%9D%82%E8%B0%88/" style="font-size: 1.25em; color: rgb(126, 119, 26)">杂谈</a><a href="/tags/%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE/" style="font-size: 1.19em; color: rgb(46, 37, 115)">博客配置</a><a href="/tags/Socket-Programming/" style="font-size: 1.19em; color: rgb(84, 189, 118)">Socket Programming</a><a href="/tags/%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA/" style="font-size: 1.19em; color: rgb(132, 100, 72)">算法概论</a><a href="/tags/Wireshark-Lab/" style="font-size: 1.2em; color: rgb(97, 100, 162)">Wireshark Lab</a><a href="/tags/Python%E5%B0%8F%E6%8A%80%E5%B7%A7/" style="font-size: 1.15em; color: rgb(77, 50, 63)">Python小技巧</a><a href="/tags/Flarum/" style="font-size: 1.18em; color: rgb(75, 111, 46)">Flarum</a><a href="/tags/pytorch/" style="font-size: 1.16em; color: rgb(59, 114, 124)">pytorch</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/" style="font-size: 1.15em; color: rgb(4, 138, 106)">深度学习基本知识</a><a href="/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" style="font-size: 1.16em; color: rgb(70, 16, 92)">离散数学</a><a href="/tags/Coursera-Programming-Languages/" style="font-size: 1.4em; color: rgb(109, 44, 196)">Coursera Programming Languages</a><a href="/tags/GAMES101/" style="font-size: 1.44em; color: rgb(171, 109, 194)">GAMES101</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F/" style="font-size: 1.27em; color: rgb(66, 22, 49)">深度学习系统</a><a href="/tags/OSTEP/" style="font-size: 1.3em; color: rgb(94, 41, 174)">OSTEP</a><a href="/tags/%E5%8F%98%E5%88%86%E6%B3%95/" style="font-size: 1.16em; color: rgb(47, 93, 189)">变分法</a><a href="/tags/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" style="font-size: 1.19em; color: rgb(12, 74, 190)">算法分析</a><a href="/tags/CS205A/" style="font-size: 1.37em; color: rgb(84, 168, 164)">CS205A</a><a href="/tags/CS224N/" style="font-size: 1.34em; color: rgb(45, 192, 130)">CS224N</a><a href="/tags/CS229/" style="font-size: 1.42em; color: rgb(74, 97, 176)">CS229</a><a href="/tags/CS231/" style="font-size: 1.33em; color: rgb(17, 199, 152)">CS231</a><a href="/tags/CS234-Reinforcement-Learning/" style="font-size: 1.15em; color: rgb(146, 154, 60)">CS234 Reinforcement Learning</a><a href="/tags/CS236-Deep-Generative-Models/" style="font-size: 1.26em; color: rgb(45, 157, 145)">CS236 Deep Generative Models</a><a href="/tags/CS50/" style="font-size: 1.25em; color: rgb(142, 1, 182)">CS50</a><a href="/tags/%E5%8C%97%E5%A4%A7C-%E6%85%95%E8%AF%BE/" style="font-size: 1.25em; color: rgb(109, 37, 191)">北大C++慕课</a><a href="/tags/David-silver-Reinforcement-Learning/" style="font-size: 1.29em; color: rgb(122, 10, 104)">David silver Reinforcement Learning</a><a href="/tags/DLHLP/" style="font-size: 1.25em; color: rgb(5, 134, 140)">DLHLP</a><a href="/tags/DSP/" style="font-size: 1.27em; color: rgb(7, 150, 75)">DSP</a><a href="/tags/%E8%8A%AF%E7%89%87%E8%AE%BE%E8%AE%A1/" style="font-size: 1.19em; color: rgb(158, 184, 162)">芯片设计</a><a href="/tags/EE261/" style="font-size: 1.44em; color: rgb(145, 137, 150)">EE261</a><a href="/tags/EE263/" style="font-size: 1.4em; color: rgb(192, 142, 66)">EE263</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">二月 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/01/"><span class="card-archive-list-date">一月 2023</span><span class="card-archive-list-count">17</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/12/"><span class="card-archive-list-date">十二月 2022</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/11/"><span class="card-archive-list-date">十一月 2022</span><span class="card-archive-list-count">9</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/10/"><span class="card-archive-list-date">十月 2022</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/09/"><span class="card-archive-list-date">九月 2022</span><span class="card-archive-list-count">11</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/08/"><span class="card-archive-list-date">八月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/07/"><span class="card-archive-list-date">七月 2022</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">796</div></div><div class="webinfo-item"><div class="item-name">已运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2018-03-09T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">本站总字数 :</div><div class="item-count">1431.7k</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-02-02T15:48:42.666Z"></div></div></div></div><div class="card-widget user-map" id="user-map" style="order: 3"><div class="item-headline"><i class="fas fa-heartbeat"></i><span>访客地图</span></div><div class="item-content"><script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=q1NruxJWhX9RKKuuAGRqK9PyMZ1xNURePPrNM8SEbR4"></script></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2023 By Doraemonzzz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>(() => {
  function loadValine () {
    function initValine () {
      let initData = {
        el: '#vcomment',
        appId: 'IpnmxCW9CvYWIXbol5QXsegX-MdYXbMMI',
        appKey: 'w57DVCdbxcyB1TYYagMIMJIU',
      }
      
      const valine = new Valine(initData)
    }

    if (typeof Valine === 'function') initValine() 
    else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
  }

  window.pjax ? loadValine() : window.addEventListener('load', loadValine)
})()</script></div><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.17.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=monsterid'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://IpnmxCW9.api.lncldglobal.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'IpnmxCW9CvYWIXbol5QXsegX-MdYXbMMI',
        "X-LC-Key": 'w57DVCdbxcyB1TYYagMIMJIU',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>