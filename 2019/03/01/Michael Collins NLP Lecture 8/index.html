<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Michael Collins NLP Lecture 8 | Doraemonzzz</title><meta name="keywords" content="Michael Collins NLP"><meta name="author" content="Doraemonzzz"><meta name="copyright" content="Doraemonzzz"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="课程主页：http:&#x2F;&#x2F;www.cs.columbia.edu&#x2F;~cs4705&#x2F; 课程网盘地址： 链接：https:&#x2F;&#x2F;pan.baidu.com&#x2F;s&#x2F;1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3  这一讲主要介绍了基于短语的翻译模型。">
<meta property="og:type" content="article">
<meta property="og:title" content="Michael Collins NLP Lecture 8">
<meta property="og:url" content="http://doraemonzzz.com/2019/03/01/Michael%20Collins%20NLP%20Lecture%208/index.html">
<meta property="og:site_name" content="Doraemonzzz">
<meta property="og:description" content="课程主页：http:&#x2F;&#x2F;www.cs.columbia.edu&#x2F;~cs4705&#x2F; 课程网盘地址： 链接：https:&#x2F;&#x2F;pan.baidu.com&#x2F;s&#x2F;1KijgO7yjL_MVCC9zKZ7Jdg提取码：t1i3  这一讲主要介绍了基于短语的翻译模型。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2019-03-01T14:42:00.000Z">
<meta property="article:modified_time" content="2020-04-29T02:19:36.955Z">
<meta property="article:author" content="Doraemonzzz">
<meta property="article:tag" content="Michael Collins NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://doraemonzzz.com/2019/03/01/Michael%20Collins%20NLP%20Lecture%208/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Michael Collins NLP Lecture 8',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-04-29 10:19:36'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">610</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Doraemonzzz</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Michael Collins NLP Lecture 8</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-03-01T14:42:00.000Z" title="发表于 2019-03-01 22:42:00">2019-03-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-04-29T02:19:36.955Z" title="更新于 2020-04-29 10:19:36">2020-04-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/NLP/">NLP</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Michael Collins NLP Lecture 8"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>课程主页：<a target="_blank" rel="noopener" href="http://www.cs.columbia.edu/~cs4705/">http://www.cs.columbia.edu/~cs4705/</a></p>
<p>课程网盘地址：</p>
<p>链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg">https://pan.baidu.com/s/1KijgO7yjL_MVCC9zKZ7Jdg</a><br>提取码：t1i3 </p>
<p>这一讲主要介绍了基于短语的翻译模型。</p>
<span id="more"></span>
<h2 id="Chapter-6-基于短语的翻译模型"><a href="#Chapter-6-基于短语的翻译模型" class="headerlink" title="Chapter 6 基于短语的翻译模型"></a>Chapter 6 基于短语的翻译模型</h2><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h3><p>在之前的讲座中，我们已经看到了IBM翻译模型1和2。在本讲义中，我们将描述基于短语的翻译模型。 基于短语的翻译模型在IBM模型上提供了大大改进的翻译，并为许多语言对提供了最先进的翻译。<br>    至关重要的是，基于短语的翻译模型允许在源语言或目标语言方面具有多个单词的词汇项：例如，我们可能有词汇项</p>
<script type="math/tex; mode=display">
\text{(le chien, the dog)}</script><p>该词汇项指定法语中的字符串$\text{le chien}$可以用英语翻译为$\text{ the dog}$。在源语言或目标语言方面使用多单词表达的选项与IBM模型1和2有很大不同，后者基本上是单词到单词的翻译模型（即，它们假设每个法语单词都是由单个英文单词生成）。 多单词表达在翻译中非常有用；这是基于短语的翻译模型所带来改进的主要原因。</p>
<p>更正式地，基于短语的词库定义如下：</p>
<h5 id="定义-1（基于短语的词库）"><a href="#定义-1（基于短语的词库）" class="headerlink" title="定义 1（基于短语的词库）"></a>定义 1（基于短语的词库）</h5><p>基于短语的词库$\mathcal L$是一组词汇项，其中每个词汇项是元组$(f,e,g)$，其中：</p>
<ul>
<li>$f$是一个或多个外语单词的序列。</li>
<li>$e$是一个或多个英语单词的序列。</li>
<li>$g$是词汇项的得分。得分可以是实数中的任何值。</li>
</ul>
<p>注意到没有限制要求词汇项中的外语单词和英语单词的数量应该相等。 例如，允许以下项：</p>
<script type="math/tex; mode=display">
(\text{au, to the, } 0.5)\\
(\text{au banque, to the bank, } 0.01) \\
(\text{allez au banque, go to the bank, }2.5)</script><p>（类似的情况下，英语单词少于法语单词，也是允许的）。在词汇项的定义中的这种灵活性是重要的，因为在许多情况下，具有外语和英语单词的数量不相等的词汇项是非常有用的。 </p>
<p>我们很快就会描述如何在翻译中使用短语词汇$\mathcal L$。 然而，首先，我们将描述如何从一组翻译样本中学习短语词库。</p>
<h3 id="2-从翻译样例中学习短语词汇"><a href="#2-从翻译样例中学习短语词汇" class="headerlink" title="2.从翻译样例中学习短语词汇"></a>2.从翻译样例中学习短语词汇</h3><p>和以前一样，我们假设我们的训练数据包括英语句子$e^{(k)}=e^{(k)}_1…e^{(k)}_{l_k}$与配对的法语句子$f^{(k)}=f^{(k)}_1…f^{(k)}_{m_k}$，$k=1…n$。 这里整数$l_k$是第$k$个英语句子的长度，$e^{(k)}_j$是第$k$个英语句子中的第$j$个单词。 整数$m_k$是第$k$个法语句子的长度，$f^{(k)}_i$是第$k$个法语句子中的第$i$个单词。</p>
<p>除了句子本身之外，我们还假设每个训练样本都有一个对齐矩阵。第$k$个样本的对齐矩阵$A^{(k)}$形状为$l_k \times m_k$，其中</p>
<script type="math/tex; mode=display">
A^{(k)}_{i,j}=\begin{cases}
1 & 如果法语中第i个单词和英语中第j个单词对齐\\
0 & 其他
\end{cases}</script><p>请注意，此表示形式比IBM模型1和2所考虑的对齐更为通用。在这些模型中，我们有对齐变量$a_i,i\in \{1…m_k\}$，指定了第$i$个法语单词所对应的英语单词。根据定义，在IBM模型1和2中，每个法语单词只能与单个英语单词对齐。利用对齐矩阵$A^{(k)}_{i,j}$，对齐可以是多对多的；例如，给定的法语单词可以与多于一个英语单词对齐（即，对于给定的$i$，我们可以有多个$j$满足$A^{(k)}_{i,j}=1$）。</p>
<p>关于如何导出对齐矩阵$A^{(k)}$，我们还不知道。在实际中，常见的方法类似于以下内容。首先，我们使用前一讲中描述的EM算法训练IBM模型2。其次，我们使用各种启发式方法从每个训练样本的IBM模型输出中提取对齐矩阵。具体来说，一个非常简单的方法如下（该方法太朴素，无法在实际中使用，仅作为示例）：</p>
<ul>
<li><p>使用训练样本$e^{(k)},f^{(k)}$，$k=1…n$，使用前一讲中描述的EM算法训练IBM模型2。对于任何英语字符串$e$，法语字符串$f$和法语长度$m$，该模型给出条件概率$p(f,a|e,m)$。</p>
</li>
<li><p>对于每个训练样本，定义</p>
<script type="math/tex; mode=display">
a^{(k)} =\arg \max_a p(f^{(k)},a|e^{(k)},m_k)</script><p>也就是说，对于第$k$个样本，$a^{(k)}$是该模型下最可能的对齐（参见IBM模型1和2中有关如何计算它的注释）。</p>
</li>
<li><p>定义</p>
<script type="math/tex; mode=display">
A^{(k)}_{i,j}=\begin{cases}
1 & a_i^{(k)}=j\\
0 & 其他
\end{cases}</script></li>
</ul>
<p>例如对于句子</p>
<script type="math/tex; mode=display">
\text{English: Mary did not slap the green witch}\\
\text{Spanish: Maria no daba una bofetada a la bruja verde}</script><p>我们可以得到如下对齐矩阵：</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022003.jpg?raw=true" alt=""></p>
<p>该方法的问题是不是多对多。另一种方法如下（见PPT）</p>
<ul>
<li>步骤1：为$p(f|e)$训练IBM模型2，并为每个$(e,f)$对提出最可能的对齐。</li>
<li>步骤2：为$p(e|f)$训练IBM模型2，并为每个$(e,f)$对提出最可能的对齐。</li>
</ul>
<p>我们现在有两个对齐：<strong>将两个对齐的交点作为起点</strong>。</p>
<p>例如对于上例，得到两个对齐：</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022004.jpg?raw=true" alt=""></p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022005.jpg?raw=true" alt=""></p>
<p>接下来以两者的交作为起点：</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022006.jpg?raw=true" alt=""></p>
<p>接下来启发式的算法如下：</p>
<ul>
<li>仅探索$p(f|e)$和$p(e|f)$对齐的并。</li>
<li>一次添加一个对齐点。</li>
<li>仅添加当前没有对齐的单词。</li>
<li>一开始，将自己限制在当前对齐点的“邻居”（邻接或对角线）的对齐点。</li>
<li>稍后，考虑其他对齐点。</li>
</ul>
<p>利用上述方法得到的对齐矩阵如下：</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022007.jpg?raw=true" alt=""></p>
<p>现在假设我们已经为每个训练样本导出了一个对齐矩阵，我们现在可以描述从一组翻译样本中提取基于短语的词库的方法。 图1显示了用于此目的的简单算法。 算法的输入是一组翻译样本，每个训练样本都有一个对齐矩阵。 该算法迭代所有训练样本（$k=1…n$），并覆盖所有可能的短语对，其中短语对是一对$(s,t),(s’,t’)$，其中$(s,t)$是源语言句子中的子序列，并且$(s’,t’)$是目标语言句子中的子序列。例如，考虑包含以下句子的训练样本：</p>
<script type="math/tex; mode=display">
f^{(k)} =\text{wir mussen auch diese kritik ernst nehmen} \\
e^{(k)} = \text{we must also take these criticisms seriously}</script><p>那么$(s, t) = (1,2), (s’, t’) = (2, 5)$将对应潜在的词汇项</p>
<script type="math/tex; mode=display">
\text{wir mussen, must also take these}</script><p>对于每个可能的$(s,t),(s’,t’)$对，我们测试它是否与对齐矩阵$A^{(k)}$一致：函数$\text{consistent}(A^{(k)},(s,t),(s’,t’))$，如果可能的词汇项$(s,t),(s’,t’)$与训练样本的对齐矩阵一致，则返回true。有关$\text{consistent}$函数的定义，请参见图2。</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022001.jpg?raw=true" alt=""></p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022002.jpg?raw=true" alt=""></p>
<p>对于那些一致的短语，我们将词条$(f,e)$添加到词库中，其中$f=f_s…f_t,e=e_{s’}…e_{t’}$。我们还增加计数$c(e,f)$和$c(e )$，对应于于在数据中看到词汇条目$(f,e)$的次数，$c(e )$对应于看到英语字符串$e$和任何外文短语$f$配对的次数。最后，在提取了语料库的所有词汇条目后，我们将任何短语$(f,e)$的分数定义为</p>
<script type="math/tex; mode=display">
\log \frac{c(e,f)}{c(e)}</script><p>这可以被解释为外语短语$f$关于给定英语短语$e$的对数条件概率的估计。</p>
<p>值得注意的是，这些概率在某种意义上是启发式的——即不清楚什么概率模型是整体模型的基础。但是，在使用模型进行翻译时，它们将非常有用。</p>
<h3 id="3-基于短语的模型翻译"><a href="#3-基于短语的模型翻译" class="headerlink" title="3.基于短语的模型翻译"></a>3.基于短语的模型翻译</h3><p>前面描述了如何从一组训练样本中导出基于短语的词库。 在本节中，我们将描述如何使用基于短语的词库来定义给定输入句子的一组翻译；每个这样的翻译如何在模型下获得分数；最后，我们将介绍如何搜索输入句子的最高得分翻译，从而提供翻译算法。</p>
<h4 id="3-1-短语和衍生词"><a href="#3-1-短语和衍生词" class="headerlink" title="3.1 短语和衍生词"></a>3.1 短语和衍生词</h4><p>基于短语的翻译模型的输入是具有$n$个单词的源语言句子，$x=x_1…x_n$。 输出是目标语言中的句子。 本节中的示例将使用德语作为源语言，使用英语作为目标语言。 我们将使用德语句子</p>
<script type="math/tex; mode=display">
\text{wir mussen auch diese kritik ernst nehmen}</script><p>作为一个例子。</p>
<p>基于短语的翻译模型的一个关键组成部分是基于短语的词库，它将源语言中的单词序列与目标语言中的单词序列配对，如本讲义前面部分所述。 例如，与上面显示的德语句子相关的词汇项包括</p>
<script type="math/tex; mode=display">
\begin{aligned}
&(\text{wir mussen, we must})\\
&(\text{wir mussen auch, we must also})\\
&(\text{ernst, seriously})
\end{aligned}</script><p>等等。 每个短语项都有一个相关的分数，可以取任何正值或负值。 如前所述，估计短语分数的一种非常简单的方法是定义</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
g(f,e) =\log \frac{c(e,f)}{c(e)} \tag 1
\end{eqnarray*}</script><p>其中$f$是外语词汇序列，$e$是英语单词序列，$c(e,f)$和$c(e)$是从某些语料库中获取的计数。 例如，我们有</p>
<script type="math/tex; mode=display">
g(\text{wir mussen, we must})= \log \frac{c(\text{we must, wir mussen})}{c(\text{we must})}</script><p>分数为外语短语$f$关于给定英语短语$e$的对数条件概率。</p>
<p>我们介绍以下符号。 对于特定输入（源语言）句子$x_1…x_n$，短语是元组$(s,t,e)$，表示源语言句子中的子序列$x_s…x_t$可以翻译为目标语言字符串$e$，使用基于短语的词库中的项。 例如，短语$(1,2,\text{we must})$将指定子字符串$x_1x_2$可以被翻译为$\text{we must}$。 每个短语$p=(s,t,e)$在模型下接收得分$g(p) \in \mathbb R$。 对于给定的短语$p$，我们将使用$s(p),t(p),e(p)$来指代其三个分量。 我们将使用$\mathcal P$来代表输入句子$x$的所有可能短语的集合。</p>
<p>请注意，对于给定的输入句子$x_1…x_n$，计算可能的短语集合$\mathcal P$很简单。我们只考虑$x_1…x_n$的每个子字符串，并包括短语词库中所有以子字符串作为英语字符串的项。我们最终可能会有一个以上的短语项。 </p>
<p>衍生词$y$则是有限的短语序列，$p_1,p_2,…,p_L$，其中每个$p_j$，$j\in \{1…L\}$是$\mathcal P$的成员。长度$L$可以是任何正整数值。对于任何衍生词$y$，我们使用$e(y)$来代表由$y$定义的基础翻译，其通过连接字符串$e(p_1),e(p_2),…,e(p_L)$而得到。 例如，如果</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
y = \text{(1, 3, we must also), (7, 7, take), (4, 5, this criticism), (6, 6, seriously)} \tag 2
\end{eqnarray*}</script><p>那么</p>
<script type="math/tex; mode=display">
e(y) = \text{we must also take this criticism seriously}</script><h4 id="3-2-有效衍生词集"><a href="#3-2-有效衍生词集" class="headerlink" title="3.2 有效衍生词集"></a>3.2 有效衍生词集</h4><p>我们将使用$\mathcal Y(x)$来表示输入句子$x=x_1…x_n $的有效衍生词集。 $\mathcal Y(x)$是长度有限的短语序列$p_1…p_L$的结合，满足以下条件：</p>
<ul>
<li><p>每个$p_k$，$k\in \{1…L\}$是$x_1…x_n$的短语$\mathcal  P$的成员。（回想一下，每个$p_k$是三元组$(s,t,e)$。）</p>
</li>
<li><p>每个单词只翻译一次。 更正式地说，对于衍生词$y=p_1…p_L$，我们定义</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
y(i)=\sum_{k=1}^ L [\![  s(p_k) \le i \le t(p_k)]\!]
\end{eqnarray*}</script><p>是单词$i$被翻译的次数（如果$\pi$是真，那么$[![ \pi ]!]$为$1$，否则为$0$），那么我们必须有</p>
<script type="math/tex; mode=display">
y(i) =1</script><p>对$i=1…n$</p>
</li>
<li><p>对$k\in \{1…L-1\}$，</p>
<script type="math/tex; mode=display">
|t(p_k) + 1-s(p_{k+1})| \le  d</script><p>其中$d\ge 0$是模型的参数。 另外，我们必须有</p>
<script type="math/tex; mode=display">
|1-s(p_1)|\le d</script></li>
</ul>
<p>前两个条件应该是明确的。 最后一个条件取决于参数$d$，值得更多解释。</p>
<p>参数$d$是连续短语彼此之间的距离的限制，并且通常被称为失真限制（distortion limit）。为了说明这一点，请考虑我们之前的示例衍生词：</p>
<script type="math/tex; mode=display">
y = \text{(1, 3, we must also), (7, 7, take), (4, 5, this criticism), (6, 6, seriously)}</script><p>在这种情况下，$y=p_1p_2p_3 p_4$（即，短语的数量$L$等于$4$）。 为了论证，假设失真参数$d$等于$4$。</p>
<p>我们现在将解决以下问题：这种衍生词是否满足条件</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
|t(p_k) + 1-s(p_{k+1})| \le  d \tag 4
\end{eqnarray*}</script><p>对$k=1…3$？首先考虑$k = 1$的情况。在这种情况下，我们有$t(p_1)= 3,s(p_2)= 7$。因此</p>
<script type="math/tex; mode=display">
|t(p_1) + 1-s(p_2)| =|3+1-7| =3</script><p>对于$k = 1$，满足公式$4$中的约束。可以看出，$|t(p_1) + 1-s(p_2)|$的值是短语$p_1$和$p_2$在句子中相互之间的距离的度量。 失真限制指定连续短语必须彼此相对接近。</p>
<p>现在考虑$k = 2$的约束。在这种情况下我们有</p>
<script type="math/tex; mode=display">
|t(p_2) + 1-s(p_3)| =|7+1-4| =4</script><p>所以约束满足（回想一下，我们假设$d = 4$）。对于$k = 3$，我们有</p>
<script type="math/tex; mode=display">
|t(p_3) + 1-s(p_4)| =|5+1-6| =0</script><p>最后，我们需要检查约束</p>
<script type="math/tex; mode=display">
|1-s(p_1)| \le d</script><p>对于此示例，$s(p_1)=1$，所以满足约束。 这个最终约束确保序列中的第一个短语$p_1$离句子的开头不太远。</p>
<p>作为一个因为不满足失真约束的无效的衍生的例子，考虑</p>
<script type="math/tex; mode=display">
y = \text{(1, 2, we must), (7, 7, take), (3, 3, also), (4, 5, this criticism), (6, 6, seriously)}</script><p>在这种情况下，可以验证</p>
<script type="math/tex; mode=display">
|t(p_2) + 1-s(p_3)| =|7+1-3| =5</script><p>大于失真限制$d=4$。</p>
<p>失真限制的动机是双重的：</p>
<ol>
<li>它减少了模型中的搜索空间，使得模型的翻译更加高效。</li>
<li>根据经验，它经常被证明可以提高翻译效果。对于许多语言对，最好不要允许相互之间距离较长的连续短语，因为这会导致不好的翻译。</li>
</ol>
<p>然而，应该注意的是，失真限制实际上是用于建模语言之间的词序差异的相当粗略的方法。 在课程的后面，我们将看到试图改进这种方法的系统。</p>
<h4 id="3-3-衍生词的得分"><a href="#3-3-衍生词的得分" class="headerlink" title="3.3 衍生词的得分"></a>3.3 衍生词的得分</h4><p>接下来的问题如下：我们如何评估衍生词的得分？也就是说，我们如何定义函数$f(y)$，它为句子的每个可能的衍生词分配一个分数？ 源语言句子$x$在该模型下的最佳翻译将是</p>
<script type="math/tex; mode=display">
\arg \max_{y\in \mathcal Y(x)} f(y)</script><p>在基于短语的系统中，任何衍生词$y$的得分按如下方式计算：</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
f(y) = h(e(y)) + \sum_{k=1}^L g(p_k)
+\sum_{k=1}^{L-1}\eta \times |t(p_k) + 1-s(p_{k+1})| 
\tag 5
\end{eqnarray*}</script><p>该分数的组成部分如下：</p>
<ul>
<li><p>如前所述，$e(y)$是衍生词$y$的目标语言字符串。$h(e(y))$是三元语言模型下字符串$e(y)$的对数概率。 因此，如果$e(y)=e_1…e_m$，那么</p>
<script type="math/tex; mode=display">
h(e(y))= \log \prod_{i=1}^m q(e_i|e_{i-2},e_{i-1}) =
\sum_{i=1}^m  \log q(e_i|e_{i-2},e_{i-1})</script><p>其中$q(e_i|e_{i-2},e_{i-1})$是三元语言模型下，单词$e_i$在二元组$e_{i-2},e_{i-1}$之后的概率。</p>
</li>
<li><p>如前所述，$g(p_k)$是短语$p_k$的得分（例如，公式$1$为一种可能的方法来定义$g(p)$）。</p>
</li>
<li><p>$\eta$是模型的“失真参数”。它通常可以是任何正值或负值，但在实际中它几乎总是负的。每一项</p>
<script type="math/tex; mode=display">
|t(p_k) + 1-s(p_{k+1})|</script><p>对应于短语$p_k$和$p_{k + 1}$相互远离的惩罚（假设$\eta $为负数）。因此，除了对连续短语之间的距离具有硬约束之外，我们还具有软约束（即，与该距离线性增加的惩罚）。</p>
</li>
</ul>
<p>给定这些定义，源语言句子$x=x_1…x_n $在该模型下的最佳翻译是</p>
<script type="math/tex; mode=display">
\arg \max_{y\in \mathcal Y(x)} f(y)</script><h4 id="3-4-总结"><a href="#3-4-总结" class="headerlink" title="3.4 总结"></a>3.4 总结</h4><h6 id="定义-2-（基于短语的翻译模型）"><a href="#定义-2-（基于短语的翻译模型）" class="headerlink" title="定义 2 （基于短语的翻译模型）"></a>定义 2 （基于短语的翻译模型）</h6><p>基于短语的翻译模型是元组$(\mathcal L, h,d,\eta)$，其中：</p>
<ul>
<li><p>$\mathcal  L$是基于短语的词库。$\mathcal L$的每个成员是元组$(f,e,g)$，其中$f$是一个或多个外语单词的序列，$e$是一个或多个英语单词的序列，$g\in \mathbb R$是$(f,e)$的分数。</p>
</li>
<li><p>$h$是三元语言模型：也就是说，对于任何英文字符串$e_1…e_m$，</p>
<script type="math/tex; mode=display">
h(e_1...e_m) =\sum_{i=1}^m  \log q(e_i|e_{i-2},e_{i-1})</script><p>其中$q$是模型的参数，我们假设</p>
<script type="math/tex; mode=display">
e_{-1}= e_0 = *</script><p>其中*是语言模型中的特殊起始符号。</p>
</li>
<li><p>$d$是非负整数，指定模型下的失真限制。</p>
</li>
<li><p>$\eta\in \mathbb R$是模型中的失真惩罚。</p>
</li>
</ul>
<p>对于输入句子$x_1…x_n$，定义$\mathcal Y(x)$是模型$(\mathcal L, h,d,\eta)$下的有效衍生词集。 解码问题是找到</p>
<script type="math/tex; mode=display">
\arg \max_{y\in \mathcal Y(x)} f(y)</script><p>其中，假设$y=p_1p_2…p_L$，</p>
<script type="math/tex; mode=display">
f(y) = h(e(y)) + \sum_{k=1}^L g(p_k)
+\sum_{k=1}^{L-1}\eta \times |t(p_k) + 1-s(p_{k+1})|</script><h3 id="4-使用基于短语的模型进行解码"><a href="#4-使用基于短语的模型进行解码" class="headerlink" title="4.使用基于短语的模型进行解码"></a>4.使用基于短语的模型进行解码</h3><p>我们现在描述基于短语的模型的解码算法：即，试图找到</p>
<script type="math/tex; mode=display">
\begin{eqnarray*}
\arg \max_{y\in \mathcal Y(x)} f(y)

\tag 6
\end{eqnarray*}</script><p>的算法。其中，假设$y=p_1p_2…p_L$，</p>
<script type="math/tex; mode=display">
f(y) = h(e(y)) + \sum_{k=1}^L g(p_k)
+\sum_{k=1}^{L-1}\eta \times |t(p_k) + 1-s(p_{k+1})|</script><p>根据上述对$f(y)$的定义，公式$6$的问题是NP-hard；因此，我们描述的算法是一种近似算法，不能保证找到最优解。</p>
<p>算法中的第一个关键数据结构是状态。 一个状态是一个元组</p>
<script type="math/tex; mode=display">
(e_1,e_2,b,r,\alpha)</script><p>其中$e_1,e_2$是英文单词，$b$是长度为$n$的位串（bit-string）（回想一下，$n$是源语言句子的长度），$r$是一个整数，指定状态中最后一个短语的终点位置，$\alpha$是状态的得分。</p>
<p>任何短语序列都可以映射到相应的状态。 例如，序列</p>
<script type="math/tex; mode=display">
y = \text{(1, 3, we must also), (7, 7, take), (4, 5, this criticism)}</script><p>将被映射到状态</p>
<script type="math/tex; mode=display">
(\text{this, criticism}, 1111101, 5, \alpha)</script><p>状态记录了这一短语序列的翻译中的最后两个单词，即$\text{this}$和$\text{criticism}$。 位串记录哪些单词已被翻译：如果第$i$个单词已被翻译，则位串中的第$i$位等于$1$，否则为$0$。 在这种情况下，只有第$6$位是$0$，因为只有第$6$个单词没有被翻译。 值$r = 5$表示序列中的最后一个短语$\text{(4, 5, this criticism)}$在第$5$位结束。最后，$\alpha $将是部分翻译的分数，计算如下：</p>
<script type="math/tex; mode=display">
f(y) = h(e(y)) + \sum_{k=1}^L g(p_k)
+\sum_{k=1}^{L-1}\eta \times |t(p_k) + 1-s(p_{k+1})|</script><p>其中$L=3$，我们有</p>
<script type="math/tex; mode=display">
e(y) =\text{we must also take this criticism}</script><p>以及</p>
<script type="math/tex; mode=display">
p_1 = (1, 3, \text{we must also}), p_2 = (7, 7, \text{take}), 
p_3 = (4, 5, \text{this criticism})</script><p>请注意，状态仅记录衍生词中的最后两个单词：稍后将会看到，这是因为三元语言模型仅对序列中的最后两个单词敏感，因此状态仅需要记录最后两个单词。</p>
<p>我们将初始状态定义为</p>
<script type="math/tex; mode=display">
q_0 = (*, *,0^n , 0,0)</script><p>其中$0^n$是长度为$n$的位串，具有$n$个零。 我们使用$\star$来引用语言模型中的特殊起始符号。初始状态没有单词被翻译（所有位都设置为$0$）；$r$的值为$0$；得分$\alpha  $为$0$。</p>
<p>接下来，我们定义一个函数$\text{ph}(q)$，它将状态$q$映射到可以附加到$q$的短语集。 对于$\text{ph}(q)$的短语成员$p$，其中$q=(e_1,e_2,b,r,\alpha)$，必须满足以下条件：</p>
<ul>
<li><p>$p$不得与位串$b$重叠。 即，对于$i\in \{ s(p)…t(p)\}$，我们必须具有$b_i =0$。</p>
</li>
<li><p>不得违反失真限制。 更具体地说，我们必须拥有</p>
<script type="math/tex; mode=display">
|r+1 -s(p)|\le d</script><p>其中$d$是失真限制。</p>
</li>
</ul>
<p>另外，对于任何状态$q$，对于任何短语$p\in \text{ph}(q)$，我们定义</p>
<script type="math/tex; mode=display">
\text{next}(p, q)</script><p>为通过将状态$q$与短语$p$组合形成的状态。 形式上，如果$q=(e_1,e_2,b,r,\alpha)$，并且$p=(s,t,\epsilon_1…\epsilon_M)$，那么$\text{next}(p, q)$是状态$q’=(e’_1,e’_2,b’,r’,\alpha’)$，定义如下：</p>
<ul>
<li><p>首先，为方便起见，定义$\epsilon_{-1}= e_1,\epsilon_0 = e_2$。</p>
</li>
<li><p>定义$e_1’=\epsilon_{M-1},e_2’ =\epsilon_M$。</p>
</li>
<li><p>对$i\in \{s…t\}$，定义$b_i’=1$。对$i\not\in \{s…t\}$，定义$b_i’ =b_i$。</p>
</li>
<li><p>定义$r’=t$。</p>
</li>
<li><p>定义</p>
<script type="math/tex; mode=display">
\alpha' =\alpha+ g(p) +
\sum_{i=1}^M
\log q(\epsilon_{i}|\epsilon_{i-2},\epsilon_{i-1}) +\eta\times |r+1-s|</script></li>
</ul>
<p>因此，更新$e_1’$和$e_2’$被更新为记录将短语$p$附加到状态$q$而形成的翻译中的最后两个单词; $b’$是一个更新的位串，它被修改为记录单词$s…t$哪些已经翻译；$r’$简单地设置为$t$，即短语$p$的结束点；$\alpha’$是通过添加短语得分$g(p)$，语言模型对于单词$\epsilon_1…\epsilon_ M$的得分和失真项$\eta\times |r+1-s|$来计算的。</p>
<p>我们解码算法所需的最终函数是一个非常简单的函数，它测试两个状态的是否相等。 函数</p>
<script type="math/tex; mode=display">
\text{eq}(q,q')</script><p>返回真或假。假设$q=(e_1,e_2,b,r,\alpha)$，并且$q’=(e’_1,e’_2,b’,r’,\alpha’)$，当且仅当$e_1=e_1’,e_2=e_2’,b=b’,r=’r$时$\text{eq}(q,q’)$为真。</p>
<p>定义了$\text{ph}$，$\text{next}$和$\text{eq}$函数后，我们现在准备提供完整的解码算法。图3给出了基本的解码算法。该算法对$i=0…n$操纵集合$Q_i$。每个集合$Q_i$包含一组与长度为$i$的翻译相对应的状态（状态$q$的长度是$q$的位串中的$1$的个数——即，该状态下被翻译的单词数量）。最初，我们将$Q_0$设置为包含单个状态，即初始状态$q_0$。我们设置所有其他集合$Q_i $为空集（$i=1…n $）。然后我们迭代：对于每个$i\in \{1,2…n\}$，我们考虑每个$q\in \text{beam}(Q_i)$（$\text{beam}(Q_i)$是$Q_i$的一个子集，只包含$Q_i$的最高得分元素：我们将很快给出一个正式的定义）。对于每个$q\in \text{beam}(Q_i)$，我们首先计算集合$\text{ph}(q )$；然后对于每个$p\in \text{ph}(q )$，我们计算下一个状态$q’=\text{next}(p, q)$。我们将这个新状态添加到集合$Q_j$，其中$j$是状态$q’$的长度。请注意，我们总是有$j&gt;i$，因此我们总是将元素添加到比我们当前正在考虑的集合$Q_i $更先进的状态（即长度更长）。</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022008.jpg?raw=true" alt=""></p>
<p>图$4$给出了函数$\text{Add}(Q,q’,q,p)$的定义。 函数首先检查$Q$中是否存在状态$q’’$，使得$\text{eq}(q’’,q’)$为真。 如果是这种情况，那么如果$q’$的分数高于$q’’$，那么$q’$将替换$q’’$；否则$q’$不会被添加到$Q$。因此，状态$q’$和$q’’$中的只有一个保留在$Q$中。如果没有这样的状态$q’’$，则将$q’$简单地添加到$Q$。</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022009.jpg?raw=true" alt=""></p>
<p>请注意，$\text{Add}$函数记录了添加到集合$Q$的任何状态$q’$的反向指针$\text{bp}(q’)$。这些反向指针将允许我们恢复最高评分状态的最终翻译。 实际上，算法的最后一步是：</p>
<ul>
<li>1）在集合$Q_n$中找到最高得分状态$q$。</li>
<li>2）从这个状态恢复最高得分翻译，通过追踪状态的反向指针。</li>
</ul>
<p>最后，我们需要定义函数$ \text{beam}(Q)$；这个定义在图$5$中给出。该函数首先计算$\alpha ^<em>$，即$Q$中任何一个状态的最高分；它然后丢弃任何小于$\alpha^</em> -\beta$的状态，其中$\beta&gt;0$是解码算法的波束宽度（beam-width）。</p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2019022010.jpg?raw=true" alt=""></p>
<h2 id="本讲测验题"><a href="#本讲测验题" class="headerlink" title="本讲测验题"></a>本讲测验题</h2><h3 id="Coursera部分"><a href="#Coursera部分" class="headerlink" title="Coursera部分"></a>Coursera部分</h3><h4 id="1"><a href="#1" class="headerlink" title="1."></a>1.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042801.jpg?raw=true" alt=""></p>
<script type="math/tex; mode=display">
a_3=4</script><h4 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042802.jpg?raw=true" alt=""></p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042803.jpg?raw=true" alt=""></p>
<script type="math/tex; mode=display">
3</script><h4 id="3"><a href="#3" class="headerlink" title="3."></a>3.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042804.jpg?raw=true" alt=""></p>
<p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042805.jpg?raw=true" alt=""></p>
<p>(a),(b),(e)</p>
<h4 id="4"><a href="#4" class="headerlink" title="4."></a>4.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042806.jpg?raw=true" alt=""></p>
<p>(a),(c),(d)</p>
<h4 id="5"><a href="#5" class="headerlink" title="5."></a>5.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042807.jpg?raw=true" alt=""></p>
<p>(a),(c),(d)</p>
<h4 id="6"><a href="#6" class="headerlink" title="6."></a>6.</h4><p><img src="https://github.com/Doraemonzzz/md-photo/blob/master/Michael%20Collins%20NLP/Lecture%208/2020042808.jpg?raw=true" alt=""></p>
<p>(b),(c),(f)</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Doraemonzzz</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://doraemonzzz.com/2019/03/01/Michael%20Collins%20NLP%20Lecture%208/">http://doraemonzzz.com/2019/03/01/Michael%20Collins%20NLP%20Lecture%208/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://doraemonzzz.com" target="_blank">Doraemonzzz</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Michael-Collins-NLP/">Michael Collins NLP</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/03/02/Michael%20Collins%20NLP%20Lecture%209/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Michael Collins NLP Lecture 9</div></div></a></div><div class="next-post pull-right"><a href="/2019/03/01/Michael%20Collins%20NLP%20Lecture%207/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Michael Collins NLP Lecture 7</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/04/08/Michael Collins NLP Homework 1/" title="Michael Collins NLP Homework 1"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-08</div><div class="title">Michael Collins NLP Homework 1</div></div></a></div><div><a href="/2020/04/21/Michael Collins NLP Homework 2/" title="Michael Collins NLP Homework 2"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-04-21</div><div class="title">Michael Collins NLP Homework 2</div></div></a></div><div><a href="/2020/05/07/Michael Collins NLP Homework 3/" title="Michael Collins NLP Homework 3"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-07</div><div class="title">Michael Collins NLP Homework 3</div></div></a></div><div><a href="/2020/05/18/Michael Collins NLP Homework 4/" title="Michael Collins NLP Homework 4"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-05-18</div><div class="title">Michael Collins NLP Homework 4</div></div></a></div><div><a href="/2019/01/24/Michael Collins NLP Lecture 1/" title="Michael Collins NLP Lecture 1"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-24</div><div class="title">Michael Collins NLP Lecture 1</div></div></a></div><div><a href="/2019/03/03/Michael Collins NLP Lecture 11/" title="Michael Collins NLP Lecture 11"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-03-03</div><div class="title">Michael Collins NLP Lecture 11</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Doraemonzzz</div><div class="author-info__description">个人博客，主要记录有关机器学习，数学以及计算机科学的笔记</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">610</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">59</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Doraemonzzz" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/doraemon_zzz@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-6-%E5%9F%BA%E4%BA%8E%E7%9F%AD%E8%AF%AD%E7%9A%84%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">Chapter 6 基于短语的翻译模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.</span> <span class="toc-text">1.介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-1%EF%BC%88%E5%9F%BA%E4%BA%8E%E7%9F%AD%E8%AF%AD%E7%9A%84%E8%AF%8D%E5%BA%93%EF%BC%89"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">定义 1（基于短语的词库）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E4%BB%8E%E7%BF%BB%E8%AF%91%E6%A0%B7%E4%BE%8B%E4%B8%AD%E5%AD%A6%E4%B9%A0%E7%9F%AD%E8%AF%AD%E8%AF%8D%E6%B1%87"><span class="toc-number">1.2.</span> <span class="toc-text">2.从翻译样例中学习短语词汇</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%9F%BA%E4%BA%8E%E7%9F%AD%E8%AF%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%BF%BB%E8%AF%91"><span class="toc-number">1.3.</span> <span class="toc-text">3.基于短语的模型翻译</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E7%9F%AD%E8%AF%AD%E5%92%8C%E8%A1%8D%E7%94%9F%E8%AF%8D"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 短语和衍生词</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-%E6%9C%89%E6%95%88%E8%A1%8D%E7%94%9F%E8%AF%8D%E9%9B%86"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 有效衍生词集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-%E8%A1%8D%E7%94%9F%E8%AF%8D%E7%9A%84%E5%BE%97%E5%88%86"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 衍生词的得分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-%E6%80%BB%E7%BB%93"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 总结</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-2-%EF%BC%88%E5%9F%BA%E4%BA%8E%E7%9F%AD%E8%AF%AD%E7%9A%84%E7%BF%BB%E8%AF%91%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">1.3.4.0.1.</span> <span class="toc-text">定义 2 （基于短语的翻译模型）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%BD%BF%E7%94%A8%E5%9F%BA%E4%BA%8E%E7%9F%AD%E8%AF%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E8%A7%A3%E7%A0%81"><span class="toc-number">1.4.</span> <span class="toc-text">4.使用基于短语的模型进行解码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E8%AE%B2%E6%B5%8B%E9%AA%8C%E9%A2%98"><span class="toc-number">2.</span> <span class="toc-text">本讲测验题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Coursera%E9%83%A8%E5%88%86"><span class="toc-number">2.1.</span> <span class="toc-text">Coursera部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1"><span class="toc-number">2.1.1.</span> <span class="toc-text">1.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2"><span class="toc-number">2.1.2.</span> <span class="toc-text">2.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3"><span class="toc-number">2.1.3.</span> <span class="toc-text">3.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4"><span class="toc-number">2.1.4.</span> <span class="toc-text">4.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5"><span class="toc-number">2.1.5.</span> <span class="toc-text">5.</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6"><span class="toc-number">2.1.6.</span> <span class="toc-text">6.</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/06/06/2021-6-6-%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA(DPV)%E4%B9%A0%E9%A2%98%E8%A7%A3%E7%AD%94%E2%80%94%E2%80%94%E7%AC%AC3%E7%AB%A0-%E5%9B%BE%E7%9A%84%E5%88%86%E8%A7%A3/" title="算法概论(DPV)习题解答——第3章 图的分解"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="算法概论(DPV)习题解答——第3章 图的分解"/></a><div class="content"><a class="title" href="/2021/06/06/2021-6-6-%E7%AE%97%E6%B3%95%E6%A6%82%E8%AE%BA(DPV)%E4%B9%A0%E9%A2%98%E8%A7%A3%E7%AD%94%E2%80%94%E2%80%94%E7%AC%AC3%E7%AB%A0-%E5%9B%BE%E7%9A%84%E5%88%86%E8%A7%A3/" title="算法概论(DPV)习题解答——第3章 图的分解">算法概论(DPV)习题解答——第3章 图的分解</a><time datetime="2021-06-06T14:35:00.000Z" title="发表于 2021-06-06 22:35:00">2021-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/06/2021-6-6-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E7%AC%AC5%E7%AB%A0-%E4%B9%A0%E9%A2%98%E8%A7%A3%E6%9E%90/" title="深入理解计算机系统 第5章 习题解析"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深入理解计算机系统 第5章 习题解析"/></a><div class="content"><a class="title" href="/2021/06/06/2021-6-6-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F-%E7%AC%AC5%E7%AB%A0-%E4%B9%A0%E9%A2%98%E8%A7%A3%E6%9E%90/" title="深入理解计算机系统 第5章 习题解析">深入理解计算机系统 第5章 习题解析</a><time datetime="2021-06-06T07:23:00.000Z" title="发表于 2021-06-06 15:23:00">2021-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/05/2021-6-5-Stanford-Compiler-PA5%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA5翻译"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Stanford Compiler PA5翻译"/></a><div class="content"><a class="title" href="/2021/06/05/2021-6-5-Stanford-Compiler-PA5%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA5翻译">Stanford Compiler PA5翻译</a><time datetime="2021-06-05T06:12:00.000Z" title="发表于 2021-06-05 14:12:00">2021-06-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/04/2021-6-4-Stanford-Compiler-PA4%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA4翻译"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Stanford Compiler PA4翻译"/></a><div class="content"><a class="title" href="/2021/06/04/2021-6-4-Stanford-Compiler-PA4%E7%BF%BB%E8%AF%91/" title="Stanford Compiler PA4翻译">Stanford Compiler PA4翻译</a><time datetime="2021-06-03T16:17:00.000Z" title="发表于 2021-06-04 00:17:00">2021-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/06/03/2021-6-3-%E5%B7%A7%E5%A6%99%E7%9A%84Y%E8%BF%90%E7%AE%97%E7%AC%A6/" title="巧妙的Y运算符"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="巧妙的Y运算符"/></a><div class="content"><a class="title" href="/2021/06/03/2021-6-3-%E5%B7%A7%E5%A6%99%E7%9A%84Y%E8%BF%90%E7%AE%97%E7%AC%A6/" title="巧妙的Y运算符">巧妙的Y运算符</a><time datetime="2021-06-03T00:54:00.000Z" title="发表于 2021-06-03 08:54:00">2021-06-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Doraemonzzz</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>